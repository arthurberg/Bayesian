[{"path":"index.html","id":"class-1-probability-fundamentals-monte-carlo","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1 Class 1: Probability Fundamentals & Monte Carlo","text":"","code":""},{"path":"index.html","id":"example-1-binomial-flips","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1.1 Example 1: Binomial flips","text":"Example 1.1  (Binomial flips) Consider 100 flips fair coin.probability observing exactly 50 heads 100 flips fair coin?probability observing exactly 50 heads 100 flips fair coin?probability observing 50 heads?probability observing 50 heads?many heads extreme sense less 5% chance observing many heads ?many heads extreme sense less 5% chance observing many heads ?","code":"# (a)\ndbinom(50, 100, prob = 1/2)\n[1] 0.07958924\n# (b)\nsum(dbinom(50:100, 100, prob = 1/2))\n[1] 0.5397946\n1 - pbinom(49, 100, prob = 1/2)\n[1] 0.5397946\npbinom(49, 100, prob = 1/2, lower.tail = FALSE)\n[1] 0.5397946\n# (c)\nqbinom(0.95, 100, prob = 1/2)\n[1] 58\nqbinom(0.05, 100, prob = 1/2, lower.tail = FALSE)\n[1] 58\n1 - pbinom(57, 100, prob = 1/2)\n[1] 0.06660531\n1 - pbinom(58, 100, prob = 1/2)\n[1] 0.04431304"},{"path":"index.html","id":"exercise-1-marbles","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1.2 Exercise 1: Marbles","text":"Exercise 1.1  (Marbles) Suppose ’s bag containing 50 marbles marble either red yellow.Five marbles randomly selected replacement one found yellow. probability marbles bag yellow?Five marbles randomly selected replacement one found yellow. probability marbles bag yellow?Five marbles randomly selected without replacement found yellow. probability marbles bag yellow?Five marbles randomly selected without replacement found yellow. probability marbles bag yellow?","code":""},{"path":"index.html","id":"example-2-gemstones","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1.3 Example 2: Gemstones","text":"Example 1.2  (Gemstones) Suppose \\(n\\) bags labeled \\(1,\\ldots,n\\) bag \\(\\) containing \\(\\) rubies \\(n-\\) diamonds. Suppose bag \\(\\) selected probability directly proportional \\(\\), random gemstone selected bag. probability diamond? Provide theoretical calculation simulated approximation.","code":"n = 13\nPr_given_B = (1:n)/n\nPr_of_B = (1:n)/sum(1:n)\nsum(Pr_given_B * Pr_of_B)\n[1] 0.6923077\n(2 * n + 1)/(3 * n)\n[1] 0.6923077\n\nR = 10^6  # number of random draws\nB = 1:n\nx1 = sample(B, size = R, replace = T, prob = B)\nx2 = sapply(x1, function(x) {\n    rbinom(1, 1, prob = x/n)\n})\nmean(x2)\n[1] 0.691866"},{"path":"index.html","id":"example-3-repairs","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1.4 Example 3: Repairs","text":"Example 1.3  (Repairs) Suppose costs repair gamma distribution mean $100 standard deviation $50. many items able repair $1000?","code":"R = 10^4  # number of random draws\nX.mean = 100\nX.var = 50^2\ns = X.var/X.mean\na = X.mean/s\na * s  #mean\n[1] 100\na * s^2  #variance\n[1] 2500\n\nX = rgamma(20, shape = a, scale = s)\ncumsum(X)\n [1]   56.20787  147.30252  244.49831  296.08107  454.20257\n [6]  494.11205  532.92228  573.29182  725.97754  901.56177\n[11] 1028.94903 1172.80233 1230.39715 1266.52078 1348.17453\n[16] 1404.52642 1512.24501 1568.78050 1617.98163 1755.40670\nwhich(cumsum(X) <= 1000)\n [1]  1  2  3  4  5  6  7  8  9 10\nmax(which(cumsum(X) <= 1000))\n[1] 10\n\nres = rep(as.integer(NA), R)\nfor (i in 1:R) {\n    X = rgamma(20, shape = a, scale = s)\n    res[i] = max(which(cumsum(X) <= 1000))\n}\nmax(res)\n[1] 16\nmean(res)\n[1] 9.5916\nsd(res)\n[1] 1.604515\n\nlibrary(ggplot2)\ndf = data.frame(number = as.factor(res))\nggplot(df, aes(x = number)) + geom_bar()"},{"path":"index.html","id":"exercise-2-icer","chapter":"1 Class 1: Probability Fundamentals & Monte Carlo","heading":"1.5 Exercise 2: ICER","text":"Exercise 1.2  (ICER) Suppose patient heart failure survival time exponential mean \\(\\theta_N\\) years. Suppose heart transplant \\(\\theta_T\\) operative survival rate, , survive, survival, \\(s_P\\), follows exponential distribution mean \\(\\theta_P\\). Assume operation costs \\(D_{\\text{operation}}\\) dollars post-operative year medical costs immunosuppressants prescriptions amount \\(D_\\text{annual}\\) dollars.literature questions , use Milliman Research Report 2020 U.S. organ tissue transplants possible. Parts (g) (h) relate incremental cost-effectiveness ratio. part (g) requires Monte Carlo simulation.Identify reasonable value \\(\\theta_N\\) literature.Identify reasonable value \\(\\theta_N\\) literature.Calculated monthly mortality based value \\(\\theta_N\\) determined ().Calculated monthly mortality based value \\(\\theta_N\\) determined ().Identify reasonable value \\(\\theta_T\\) literature.Identify reasonable value \\(\\theta_T\\) literature.Identify reasonable value \\(\\theta_P\\) literature.Identify reasonable value \\(\\theta_P\\) literature.Identify reasonable value \\(D_{\\text{operation}}\\) literature.Identify reasonable value \\(D_{\\text{operation}}\\) literature.Identify reasonable value \\(D_{\\text{annual}}\\) literature.Identify reasonable value \\(D_{\\text{annual}}\\) literature.Based values found , estimate expected additional cost per year life gained transplant?Based values found , estimate expected additional cost per year life gained transplant?Calculate ratio expected additional cost expected additional benefit.Calculate ratio expected additional cost expected additional benefit.","code":""},{"path":"class-2-diagnostic-testing.html","id":"class-2-diagnostic-testing","chapter":"2 Class 2: Diagnostic Testing","heading":"2 Class 2: Diagnostic Testing","text":"","code":""},{"path":"class-2-diagnostic-testing.html","id":"example-1-pregnancy-testing","chapter":"2 Class 2: Diagnostic Testing","heading":"2.1 Example 1: Pregnancy testing","text":"Example 2.1  (Pregnancy testing) Human Chorionic Gonadotropin (hCG) hormone dramatically increases pregnancy. Levels hormone may also high individuals cancers.Levels hCG can first detected blood test 11 days conception 12-14 days conception urine test, peak first 8-11 weeks pregnancy decline level remainder pregnancy.Non-pregnant women hCG levels < 5 IU/L hCG values > 25 IU/L indicate pregnancy. Levels 5 25 IU/L often indicate early pregnancy, results need interpreted cautiously false positive results can occur range.example simulate hCG data hypothetical population non-pregnant pregnant women early pregnancy, use data study various statistics graphics used classifier assessment.ROC graphic AUC computation using ROCR package1. First “early” pregnancy simulation (mean 20 truncated normal distribution).easily identify suitable threshold graphic, redo graphic biomarker values displayed log scale.Identifying “optimal” cutoff depends costs associated false positives false negatives. can read introduction ROCR. say worse case – false positive pregnancy test false negative pregnancy test? , ’d rather false negative pleasantly surprised later, others might --pleasant surprise. reality, course, “inconclusive” option, doesn’t fit well rigid statistical classifications gives rise various confusion matrix statistics.\nfollowing calculation maximizes Youden’s index2 equal cost false positives false negatives.see cutoff corresponds minimizing sum probability false positive probability false negative demonstrated following code.graph false positives false negatives cutoff original graphic.’s calculation cost associated false positives false negatives, specifically 4 times cost false positive compared false negative.display cutoff graphic showing decreased probability false positive.Next “slightly later” pregnancy simulation (mean 30 truncated normal distribution).compute “optimal” cutoff greater cost false positive.","code":"\nlibrary(truncnorm)\nmygraph = function(mymean) {\n    x <- seq(0, 45, 0.001)\n    y1 <- dlnorm(x, mean = 1.25, sd = 1.5)\n    y2 <- dtruncnorm(x, a = 0, mean = mymean, sd = 5)\n    plot(x, y1, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n        cex.axis = 1.5, lwd = 4, ylab = \"\")\n\n    ind1 = (x >= 5 & x <= 25)\n    polygon(c(5, x[ind1], 25), c(0, y1[ind1], 0), col = \"red\",\n        border = NA)\n    polygon(c(5, x[ind1], 25), c(0, y2[ind1], 0), col = \"red\",\n        border = NA)\n\n    ind2 = (x < 5)\n    polygon(c(0, x[ind2], 5), c(0, y1[ind2], 0), col = \"blue\",\n        border = NA)\n\n    ind3 = (x > 25)\n    polygon(c(25, x[ind3], 45), c(0, y1[ind3], 0), col = \"magenta\",\n        border = NA)\n    polygon(c(25, x[ind3], 45), c(0, y2[ind3], 0), col = \"magenta\",\n        border = NA)\n\n    points(x, y1, type = \"l\", lwd = 4)\n    points(x, y2, type = \"l\", lwd = 4)\n\n    abline(v = 5, lwd = 3, lty = 3)\n    abline(v = 25, lwd = 3, lty = 3)\n    axis(1, at = 5, cex.axis = 1.5)\n    axis(1, at = 25, cex.axis = 1.5)\n}\n\nmygraph(20)  # representing very early on in the pregnancy\nmygraph(30)  # slightly later in the pregnancy\nlibrary(ROCR)\nn = 10^5\ny1 <- rlnorm(n, mean = 1.25, sd = 1.5)\ny2 <- rtruncnorm(n, a = 0, mean = 20, sd = 5)\ny3 <- rtruncnorm(n, a = 0, mean = 30, sd = 5)\ndf = data.frame(hcg = c(y1, y2), preg = c(rep(0, n), rep(1, n)))\npred1 = prediction(df$hcg, df$preg)\nperf1 <- performance(pred1, \"tpr\", \"fpr\")\nauc.perf1 = performance(pred1, measure = \"auc\")@y.values[[1]]\nplot(perf1, colorize = TRUE, downsampling = 10^3)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf1, 3)), adj = 1)\ndf = data.frame(hcg.log = log(c(y1, y2)), preg = c(rep(\"no\",\n    n), rep(\"yes\", n)))\npred2 = prediction(df$hcg.log, df$preg)\nperf2 <- performance(pred2, \"tpr\", \"fpr\")\nauc.perf2 = performance(pred2, measure = \"auc\")@y.values[[1]]\nplot(perf2, colorize = TRUE, downsampling = 10^3)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf2, 3)), adj = 1)cost.perf2 = performance(pred2, \"cost\", cost.fp = 1, cost.fn = 1)\npred2@cutoffs[[1]][which.min(cost.perf2@y.values[[1]])]\n[1] 2.37613\nmycutoff = exp(pred2@cutoffs[[1]][which.min(cost.perf2@y.values[[1]])])\nmycutoff\n[1] 10.76317J = function(x) {\n    mean(y1 > x) + mean(y2 < x)\n}\nJ.vec = Vectorize(J, \"x\")\nx = seq(0, 20, 0.1)\nx[which.min(J.vec(x))]\n[1] 11.2\nmycutoff\n[1] 10.76317\nx <- seq(0, 45, 0.001)\ny1.plot <- dlnorm(x, mean = 1.25, sd = 1.5)\ny2.plot <- dtruncnorm(x, a = 0, mean = 20, sd = 5)\n\nplot(x, y1.plot, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n    cex.axis = 1.5, lwd = 4, ylab = \"\")\n\nind1 = (x >= mycutoff)\npolygon(c(mycutoff, x[ind1], 45), c(0, y2.plot[ind1], 0), col = \"magenta\",\n    border = NA)\npolygon(c(mycutoff, x[ind1], 45), c(0, y1.plot[ind1], 0), col = \"red\",\n    border = NA)\nind2 = (x <= mycutoff)\npolygon(c(0, x[ind2], mycutoff), c(0, y1.plot[ind2], 0), col = \"blue\",\n    border = NA)\npolygon(c(0, x[ind2], mycutoff), c(0, y2.plot[ind2], 0), col = \"orange\",\n    border = NA)\n\npoints(x, y1.plot, type = \"l\", lwd = 4)\npoints(x, y2.plot, type = \"l\", lwd = 4)\n\nabline(v = mycutoff, lwd = 2, lty = 2)\nabline(v = 5, lwd = 1, lty = 3)\nabline(v = 25, lwd = 1, lty = 3)\naxis(1, at = 5, cex.axis = 1.5)\naxis(1, at = 25, cex.axis = 1.5)cost.perf3 = performance(pred2, \"cost\", cost.fp = 4, cost.fn = 1)\npred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])]\n[1] 2.681491\nexp(pred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])])\n[1] 14.60685\nx <- seq(0, 45, 0.001)\ny1.plot <- dlnorm(x, mean = 1.25, sd = 1.5)\ny2.plot <- dtruncnorm(x, a = 0, mean = 20, sd = 5)\nmycutoff = exp(pred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])])\n\nplot(x, y1.plot, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n    cex.axis = 1.5, lwd = 4, ylab = \"\")\n\nind1 = (x >= mycutoff)\npolygon(c(mycutoff, x[ind1], 45), c(0, y2.plot[ind1], 0), col = \"magenta\",\n    border = NA)\npolygon(c(mycutoff, x[ind1], 45), c(0, y1.plot[ind1], 0), col = \"red\",\n    border = NA)\nind2 = (x <= mycutoff)\npolygon(c(0, x[ind2], mycutoff), c(0, y1.plot[ind2], 0), col = \"blue\",\n    border = NA)\npolygon(c(0, x[ind2], mycutoff), c(0, y2.plot[ind2], 0), col = \"orange\",\n    border = NA)\n\npoints(x, y1.plot, type = \"l\", lwd = 4)\npoints(x, y2.plot, type = \"l\", lwd = 4)\n\nabline(v = mycutoff, lwd = 2, lty = 2)\nabline(v = 5, lwd = 1, lty = 3)\nabline(v = 25, lwd = 1, lty = 3)\naxis(1, at = 5, cex.axis = 1.5)\naxis(1, at = 25, cex.axis = 1.5)\ndf = data.frame(hcg.log = log(c(y1, y3)), preg = c(rep(\"no\",\n    n), rep(\"yes\", n)))\npred3 = prediction(df$hcg.log, df$preg)\nperf3 <- performance(pred3, \"tpr\", \"fpr\")\nauc.perf3 = performance(pred3, measure = \"auc\")@y.values[[1]]\nplot(perf3, colorize = TRUE)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf3, 3)), adj = 1)cost.perf4 = performance(pred3, \"cost\", cost.fp = 4, cost.fn = 1)\npred3@cutoffs[[1]][which.min(cost.perf4@y.values[[1]])]\n[1] 3.090492\nexp(pred3@cutoffs[[1]][which.min(cost.perf4@y.values[[1]])])\n[1] 21.9879"},{"path":"class-2-diagnostic-testing.html","id":"example-2-ppv-by-prevalence","chapter":"2 Class 2: Diagnostic Testing","heading":"2.2 Example 2: PPV by prevalence","text":"Example 2.2  (PPV prevalence) user-specified values sensitivity specificity, graph positive predictive value range prevalence values.","code":"\nsensitivity = 0.98\nspecificity = 0.999\nprevalence = 10^(-5:-1)\nppv = sensitivity * prevalence/(sensitivity * prevalence + (1 -\n    specificity) * (1 - prevalence))\nplot(log(prevalence, 10), ppv, ylab = \"Positive Predictive Value\",\n    xlab = expression(\"Log\"[10] * \"(Prevalence)\"), pch = 16)"},{"path":"class-3-bayes-theorem-practice.html","id":"class-3-bayes-theorem-practice","chapter":"3 Class 3: Bayes’ Theorem Practice","heading":"3 Class 3: Bayes’ Theorem Practice","text":"","code":""},{"path":"class-3-bayes-theorem-practice.html","id":"example-1-single-roll","chapter":"3 Class 3: Bayes’ Theorem Practice","heading":"3.1 Example 1: Single roll","text":"Example 3.1  (Single roll) Suppose friend 3 dice. One 4 sides, one 6 sides, one 8 sides. draws one die random, rolls one time without showing , reports result rolled 2. calculate probability die 4 sided die, probability 6 sided die, probability 8 sided die?","code":"# prior probabilities: P(n=4), P(n=6), P(n=8)\nprob.prior = rep(1/3, 3)\n\n# likelihood probabilities: P(roll=2 | n=4), etc.\nprob.likelihood = c(1/4, 1/6, 1/8)\n\n# posterior probabililities P(n=4 | roll=2)\nprob.posterior = prob.prior * prob.likelihood/sum(prob.prior *\n    prob.likelihood)\n\nprob.posterior\n[1] 0.4615385 0.3076923 0.2307692\n\nc(6, 4, 3)/13\n[1] 0.4615385 0.3076923 0.2307692"},{"path":"class-3-bayes-theorem-practice.html","id":"example-2-multiple-rolls","chapter":"3 Class 3: Bayes’ Theorem Practice","heading":"3.2 Example 2: Multiple rolls","text":"Example 3.2  (Multiple rolls) Now suppose 6 possible dice, one 4 sides, one 6 sides, one 8 sides, one 10 sides, one 12 sides, one 20 sides. randomly selecting die, die rolled n times outcomes reported. Numerically calculate probabilities number sides randomly selected die.","code":"dice = c(4, 6, 8, 10, 12, 20)\n\nnum.sides = sample(dice, 1)\n\nnum.rolls = 6\n\nrolls = sample(1:num.sides, num.rolls, replace = TRUE)\n\nrolls\n[1] 8 9 7 9 7 9\n\nprior = rep(1/6, 6)\n\nlikelihood = (1/dice)^num.rolls * (max(rolls) <= dice)\n\nmarginal = sum(prior * likelihood)\n\nposterior = (prior * likelihood)/marginal\n\nposterior\n[1] 0.00000000 0.00000000 0.00000000 0.74045390 0.24797651\n[6] 0.01156959\n\nbarplot(posterior, names = dice, main = paste0(\"Actual number of sides: \",\n    num.sides))"},{"path":"class-3-bayes-theorem-practice.html","id":"exercise-1-erroneous-dice","chapter":"3 Class 3: Bayes’ Theorem Practice","heading":"3.3 Exercise 1: Erroneous dice","text":"Exercise 3.1  (Erroneous dice) Suppose 6 possible dice: one 4 sides, one 6 sides, one 8 sides, one 10 sides, one 12 sides, one 20 sides. randomly selecting die, die rolled n times outcomes reported possible errors reported rolls. assume ’s error given roll, random number 1 20. Incorporate error rate likelihood uniform prior. Given vector rolls, rolls , calculate graph posterior probabilities error rate number sides.","code":"dice=c(4,6,8,10,12,20)\nnum.sides = sample(dice,1)\nn = 10\nerror.param=runif(1)\nerrors.ind=rbinom(n,1,prob=error.param)\nerrors.values = sample(1:20,sum(errors.ind),replace=T)\n\nrolls = sample(1:num.sides,n,replace=TRUE)\nrolls[which(errors.ind==1)]=errors.values\nrolls\n [1] 7 4 7 3 2 4 7 8 6 7"},{"path":"class-4-beta-binomial.html","id":"class-4-beta-binomial","chapter":"4 Class 4: Beta-binomial","heading":"4 Class 4: Beta-binomial","text":"","code":""},{"path":"class-4-beta-binomial.html","id":"exercise-1-alice-and-bob-simulation","chapter":"4 Class 4: Beta-binomial","heading":"4.1 Exercise 1: Alice and Bob simulation","text":"Exercise 4.1  (Alice Bob simulation) Verify answer Alice Bob homework exercise Monte Carlo simulation.","code":""},{"path":"class-5-covid-19-vaccine-trials-bayesian-dice.html","id":"class-5-covid-19-vaccine-trials-bayesian-dice","chapter":"5 Class 5: COVID-19 Vaccine Trials & Bayesian Dice","heading":"5 Class 5: COVID-19 Vaccine Trials & Bayesian Dice","text":"","code":""},{"path":"class-5-covid-19-vaccine-trials-bayesian-dice.html","id":"exercise-1-vaccine-efficacy","chapter":"5 Class 5: COVID-19 Vaccine Trials & Bayesian Dice","heading":"5.1 Exercise 1: Vaccine Efficacy","text":"Exercise 5.1  (Vaccine Efficacy) Reproduce plot similar Figure 3 (Senn, 2022)3 provide table ten left right endpoints graphic.","code":""},{"path":"class-5-covid-19-vaccine-trials-bayesian-dice.html","id":"exercise-2-loaded-die","chapter":"5 Class 5: COVID-19 Vaccine Trials & Bayesian Dice","heading":"5.2 Exercise 2: Loaded Die?","text":"Exercise 5.2  (Loaded Die?) introduced (Berg, 2021)4, consider three-loaded die probability rolling numbers one six 8%, 8%, 64%, 1%, 6%, respectively. die rolled suspect may three loaded die assigning prior probability 50% 50% prior probability given standard fair die equal probabilities. actuality, die probabilities 3%, 17%, 51%, 14%, 14%, 1% (corresponding numbers one six) rolled. Mimic process simulation, , given set rolls simulation, calculate posterior probability rolled die standard die. Let number rolls grow large determine die posterior probability settles ().","code":""},{"path":"class-6-stick-breaking.html","id":"class-6-stick-breaking","chapter":"6 Class 6: Stick Breaking","heading":"6 Class 6: Stick Breaking","text":"","code":""},{"path":"class-6-stick-breaking.html","id":"stick-breaking","chapter":"6 Class 6: Stick Breaking","heading":"6.1 Stick breaking","text":"Exercise 6.1  (Stick breaking) Given positive integer \\(k\\) positive numbers \\(\\alpha_i\\), \\(=1,\\ldots,k\\), simulate Dirichlet distribution via stick breaking method described (Frigyik et al, 2010).5","code":""},{"path":"class-7-taxicab-problem.html","id":"class-7-taxicab-problem","chapter":"7 Class 7: Taxicab problem","heading":"7 Class 7: Taxicab problem","text":"","code":""},{"path":"class-7-taxicab-problem.html","id":"exercise-1-taxicabs-with-jags","chapter":"7 Class 7: Taxicab problem","heading":"7.1 Exercise 1: Taxicabs with JAGS","text":"Example 7.1  (Taxicabs JAGS) simple implementation taxicab problem single sample presented using JAGS.","code":"library(R2jags)\nLoading required package: rjags\nLoading required package: coda\nLinked to JAGS 4.3.0\nLoaded modules: basemod,bugs\n\nAttaching package: 'R2jags'\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nmodel= function(){\nM ~ dcat(p1)\n# sampling distribution is uniform over first N integers\n# use step function to change p1[j] to 0 for j>N\nfor (j in 1:1000) {\np1[j] <- step(N - j + 0.01)/N\n}\nN ~ dcat(p2)\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\ndata=list(\"M\"=100)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"N\",\"M\"), n.chain=2, n.iter=100, n.thin=1, n.burn=0, DIC=FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 1\n   Total graph size: 7007\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmpAKgqWq/model1572d33e5b650.txt\", fit using jags,\n 2 chains, each with 100 iterations (first 0 discarded)\n n.sims = 200 iterations saved\n  mu.vect sd.vect    2.5% 25% 50% 75% 97.5%  Rhat n.eff\nM 100.000   0.000 100.000 100 100 100 100.0 1.000     1\nN 260.485 197.328 102.975 127 191 307 874.1 1.002   200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1)."},{"path":"class-7-taxicab-problem.html","id":"exercise-2-taxi-counter","chapter":"7 Class 7: Taxicab problem","heading":"7.2 Exercise 2: Taxi counter","text":"Exercise 7.1  (Taxi counter) Suppose taxis sampled following codeKnowing data generating mechanism, construct Bayesian estimate total number taxis (diff(myrange)+1) based data provided taxis. can use JAGS R like.","code":"\nmyrange=sort(rnbinom(2,5,mu=rgamma(2,shape=50,rate=1/200)))\ntaxis=sample(myrange[1]:myrange[2],10,replace=TRUE)"},{"path":"class-8-bayesian-shrinkage.html","id":"class-8-bayesian-shrinkage","chapter":"8 Class 8: Bayesian shrinkage","heading":"8 Class 8: Bayesian shrinkage","text":"","code":""},{"path":"class-8-bayesian-shrinkage.html","id":"exercise-1-baseball-shrinkage","chapter":"8 Class 8: Bayesian shrinkage","heading":"8.1 Exercise 1: Baseball shrinkage","text":"Exercise 8.1  (Baseball) Using baseball dataset (Efron Morris, 1977),6 compare root mean square deviation James-Stein predictions predictions Bayesian model justified prior. Implementation R, JAGS, Stan fine; reference may helpful implementation JAGS.","code":""},{"path":"class-9-bayes-estimator.html","id":"class-9-bayes-estimator","chapter":"9 Class 9: Bayes estimator","heading":"9 Class 9: Bayes estimator","text":"","code":""},{"path":"class-9-bayes-estimator.html","id":"exercise-1-world-cities","chapter":"9 Class 9: Bayes estimator","heading":"9.1 Exercise 1: World cities","text":"Exercise 9.1  (World cities) database world cities can accessed . excluding cities zero/missing values variable Population missing values variable Country Code, sample \\(n\\) cities randomly sampled without replacement probability proportional variable Population. data provided latitude city, rounded closes integer, number digits variable Population city. estimator actual country function two integers. randomly sampled city rounded integer latitude \\(lat\\), let \\(\\theta\\) country code corresponding city, let \\(d\\) predicted value country code corresponding city, let \\(pop_d\\) total population cities corresponding \\(d\\), let \\(\\Theta_{lat}\\) set country codes city country rounded integer latitude \\(lat\\). Now consider following loss function,\n\\[\nl(\\theta,d)=\n\\begin{cases}\n0, & d=\\theta\\\\\npop_d, & d\\=\\theta \\text{ }d\\\\Theta_{lat}\\\\\n\\infty, & d\\\\\\Theta_{lat}\n\\end{cases}\n\\]\ngoal provide country code predictions minimize sum losses across sampled cities.","code":""},{"path":"class-10-minimax.html","id":"class-10-minimax","chapter":"10 Class 10: Minimax","heading":"10 Class 10: Minimax","text":"","code":""},{"path":"class-10-minimax.html","id":"exercise-1-minimax-urns","chapter":"10 Class 10: Minimax","heading":"10.1 Exercise 1: Minimax urns","text":"Exercise 10.1  (Minimax urns) Consider setup “Minimax urns” example. Prepare program inputs nonegative integer values \\(r_i\\), \\(b_i\\), \\(g_i\\), positive values \\(l_i\\) (\\(=1,2\\) throughout).Identify non-randomized Bayes rules different values \\(\\lambda\\[0,1]\\) produce effective graphic shows Bayes risk Bayesian estimators \\(\\lambda\\) \\([0,1]\\).Let \\(d_j\\), \\(j=1,\\ldots,8\\) represent 8 non-randomized estimators, define \\(S\\subset\\mathbb{R}^2\\) \n\\(S=\\left\\{\\left(R(\\theta_1,d_j),R(\\theta_2,d_j)\\right)\\right\\}_{j=1}^8\\). Graph points \\(S\\) convex hull. Identify closest point convex hull origin, label point \\(M\\).point \\(M\\) (b) corresponds (possibly randomized) minimax estimator \\(d_M\\) can represented \\(d_M=(d_{\\text{red}}, d_{\\text{blue}}, d_{\\text{green}})\\), \\(d_x\\) probability selecting urn 1 color \\(X=x\\) chosen. Determine components \\(d_M\\) graph Bayes risk graphic prepared ().","code":""},{"path":"class-11-prior-distributions.html","id":"class-11-prior-distributions","chapter":"11 Class 11: Prior distributions","heading":"11 Class 11: Prior distributions","text":"Example 11.1  (Power analysis) consider sample size estimation two-arm randomized trial continuous primary outcome \\(n\\) subjects randomized arm. Assuming normal distribution primary outcome common within-treatment standard deviation \\(\\sigma\\), estimated treatment effect assumed \\(\\mathcal{N}(\\theta,2\\sigma^2/n)\\) distribution. Thus, sample size determination found \n\\[\nn=\\frac{2\\sigma^2}{\\theta^2}\\left(z_{1-\\alpha/2}+z_{1-\\beta}\\right)^2,\n\\]\n\\(z_p=\\Phi^{-1}(p)\\). Solving \\(1-\\beta\\) gives\n\\[\n\\text{Power}=\\Phi\\left(\\sqrt{\\frac{n\\theta^2}{2\\sigma^2}}-z_{1-\\alpha/2}\\right).\n\\]\nSupposing historical data suggests \\(\\theta\\) likely (interpreted 1 standard deviation) 3 7 suggests prior \\(\\theta\\sim\\mathcal{N}(5,2^2)\\). parameter \\(\\sigma\\) estimated around 10 based around 40 observations. leads \\(\\mathrm{GammaSR}(,b)\\) prior \\(\\tau=1/\\sigma^2\\) \\(/b=1/10^2\\) \\(2a=40\\); .e. \\(\\tau\\sim\\mathrm{GammaSR}(20,2000)\\). Another set priors considered: prior \\(\\sigma\\) assumed based 20 observations instead 40 (effectively power prior) leading modified prior distribution \\(\\tau\\sim\\mathrm{GammaSR}(10,1000)\\), prior \\(\\theta\\) assumed mean bias -1 standard deviation 2 constraint \\(\\theta>0\\) thus leading modified prior distribution \\(\\theta\\sim \\mathcal{N}^+(5-1,2^2+2^2)\\).Type error \\(\\alpha\\) set \\(0.05\\). Three quantities tracked: () calculated sample size \\(n\\) 90% power, (ii) power based \\(n=84\\) (frequentest estimate fixed \\(\\theta=5\\), \\(\\sigma=10\\), 90% power), (iii) \\(n=84\\), probability power least 70%.Example 11.2  (GREAT study) region early trial (GREAT) found patients suspected acute myocardial infarction lower 3-month mortality treated early .Let \\(r_j\\), \\(n_j\\), \\(p_j\\) denote number deaths, total number patients, underlying mortality rate, respectively, group \\(j\\\\{1,2\\}\\) (1=anistreplase; 2=placebo). interested conducting inference log-odds ratio mortality anistreplase group compared placebo; .e. \n\\[\n\\theta=\\log\\left\\{\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\right\\}=\\text{logit}(p_1) - \\text{logit}(p_2)\n\\]\nnatural estimator \\(\\theta\\) \n\\[\n\\hat{\\theta}=\\log\\left\\{\\frac{r_1/(n_1-r_1)}{r_2/(n_2-r_2)}\\right\\} \\approx -0.753\n\\]\n\\[\n\\text{Var}(\\hat\\theta)\\approx \\frac{1}{r_1}+\\frac{1}{r_2}+\\frac{1}{n_1-r_1}+\\frac{1}{n_2-r_2}\\approx 0.135\n\\]following Bayesian models considered.Model (normal dist effect, uniform prior): \\(\\hat\\theta\\sim\\mathcal{N}(\\theta,0.135)\\) \\(\\theta\\sim\\text{Uniform}(-10,10)\\).Model B (binomial dist rates, Jeffreys priors): \\(r_j\\sim\\text{Binomial}(p_j,n_j)\\) \\(p_j\\sim\\Beta(.5,.5)\\), \\(j=1,2\\).Model C (binomial dist rates, logit transform, clinical prior): parameters \\(p_1\\) \\(p_2\\) reparameterized terms \\(\\alpha\\) \\(\\theta\\) \n\\[\n\\begin{split}\n\\text{logit}(p_1) &= \\alpha + \\theta/2\\\\\n\\text{logit}(p_2) &= \\alpha - \\theta/2\n\\end{split}\n\\]\n\\(\\alpha\\) nuisance parameter given practically flat prior: \\(\\alpha\\sim\\mathcal{N}(0,100^2)\\). “clinical” prior \\(\\theta\\) based expert elicitation: senior cardiologist, informed one unpublished two published trials, expressed belief “expectation 15-20% reduction mortality highly plausible, extremes benefit 40% relative reduction unlikely”.translated 95% interval odds ratio (.6,1), corresponds interval (-.51,0) log-odds scale. normal distribution property leads \\(\\theta\\sim\\mathcal{N}(\\mu_0,\\sigma_{0}^2)\\), \\(\\mu_0=(-.51+0)/2=-.26\\) \\(\\sigma_0=.26/1.96\\approx .13\\).Model D (binomial dist rates, logit transform, skeptical prior): model follows approach Model C ``skeptical’’ prior placed \\(\\theta\\) avoid early stopping trials due fortuitously positive results. Specifically, prior \\(\\theta\\) constructed 95% confidence interval (.5, 2) odds ratio scale, equivalent interval (-.69,69) log-odds scale. normal distribution property leads \\(\\theta\\sim\\mathcal{N}(0,.35^2)\\).","code":"\nlibrary(rjags)\n\nmodel =\"\nmodel{\n\n tau ~ dgamma(20, 2000)\n tauDis ~ dgamma(10, 1000) # discounted by 2\n \n sigma <- 1/sqrt(tau) \n sigmaDis <- 1/sqrt(tauDis) \n \n theta ~ dnorm(5, 0.25) \n thetaDis ~ dnorm(4, 0.125) I(0,)  # 4 added to var and shifted by -1, constrained to be >0\n \n n <- 2*pow((1.28 + 1.96)*sigma/theta, 2) # n for 90% power \n power <- phi(sqrt(84/2)*theta/sigma - 1.96) # power for n = 84 \n p70 <- step(power - 0.7) # Pr(power > 70%)\n \n nDis <- 2*pow((1.28 + 1.96)*sigmaDis/thetaDis, 2) # n for 90% power \n powerDis <- phi(sqrt(84/2)*thetaDis/sigmaDis - 1.96) # power for n = 84 \n p70Dis <- step(powerDis - 0.7) # Pr(power > 70%)\n }\"\n\n\ndata=list()\njmodel <- jags.model(textConnection(model), data = data,n.chains = 3, n.adapt= 100,quiet=TRUE)\nupdate(jmodel, 100)\nmcmc_samples <- coda.samples(jmodel, variable.names=c(\"n\",\"power\",\"p70\",\"nDis\",\"powerDis\",\"p70Dis\"), n.iter=1000)\nplot(mcmc_samples)summary(mcmc_samples)\n\nIterations = 101:1100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean        SD  Naive SE Time-series SE\nn        1.416e+03 3.457e+04 6.312e+02      6.312e+02\nnDis     4.274e+07 2.326e+09 4.246e+07      4.246e+07\np70      7.007e-01 4.580e-01 8.363e-03      8.513e-03\np70Dis   5.467e-01 4.979e-01 9.090e-03      9.087e-03\npower    7.706e-01 2.661e-01 4.859e-03      4.883e-03\npowerDis 6.602e-01 3.259e-01 5.950e-03      5.950e-03\n\n2. Quantiles for each variable:\n\n             2.5%     25%      50%      75% 97.5%\nn        23.90597 53.0114  88.2762 166.9580  1730\nnDis     20.83304 58.8898 123.6087 317.4457 13747\np70       0.00000  0.0000   1.0000   1.0000     1\np70Dis    0.00000  0.0000   1.0000   1.0000     1\npower     0.10199  0.6324   0.8850   0.9829     1\npowerDis  0.04394  0.3846   0.7614   0.9719     1(mat=matrix(c(13,150,23,125),nrow=2,ncol=2,dimnames=list(c(\"death\",\"no death\"),c(\"anistreplase\",\"placebo\"))))\n         anistreplase placebo\ndeath              13      23\nno death          150     125\nfisher.test(mat)\n\n    Fisher's Exact Test for Count Data\n\ndata:  mat\np-value = 0.05002\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.2104046 1.0183476\nsample estimates:\nodds ratio \n 0.4721467 model= function(){\n\n  pr.mean[1] <- -0.26\n  pr.sd[1] <- 0.13 # clinical prior\n  \n  pr.mean[2] <- 0\n  pr.sd[2] <- 0.35 # skeptical prior\n  \n  \n  ## Likelihoods\n  \n  # Model A\n  theta.mle ~ dnorm(thetaA, 1/.135) \n  \n  # Model B\n  r.rep[1,1] ~ dbin(pB[1],n.rep[1,1])\n  r.rep[1,2] ~ dbin(pB[2],n.rep[1,2])\n  \n  thetaB <- logit(pB[1]) - logit(pB[2])\n  \n  # Model C\n  r.rep[2,1] ~ dbin(pC[1],n.rep[1,1])\n  r.rep[2,2] ~ dbin(pC[2],n.rep[1,2])\n  \n  logit(pC[1]) <- alphaC + thetaC/2\n  logit(pC[2]) <- alphaC - thetaC/2\n  \n  # Model D\n  r.rep[3,1] ~ dbin(pD[1],n.rep[1,1])\n  r.rep[3,2] ~ dbin(pD[2],n.rep[1,2])\n  \n  logit(pD[1]) <- alphaD + thetaD/2\n  logit(pD[2]) <- alphaD - thetaD/2\n  \n  ## priors\n  \n  # Model A\n  thetaA ~ dunif(-10, 10) # locally uniform prior\n  \n  # Model B\n  pB[1] ~ dbeta(0.5, 0.5) \n  pB[2] ~ dbeta(0.5, 0.5) \n  \n  # Model C (clinical prior)\n  alphaC ~ dnorm(0, 0.0001)\n  thetaC ~ dnorm(-.26, 1/pow(.13, 2))\n\n  # Model D (skeptical prior)\n  alphaD ~ dnorm(0, 0.0001)\n  thetaD ~ dnorm(0, 1/pow(.35, 2))\n}\n\nr=c(13, 23)\nn=c(163, 148)\nr.rep=array(rep(r,each=3),dim=c(3,2))\nn.rep=array(rep(n,each=3),dim=c(3,2))\n\nr.rep\n     [,1] [,2]\n[1,]   13   23\n[2,]   13   23\n[3,]   13   23\nn.rep\n     [,1] [,2]\n[1,]  163  148\n[2,]  163  148\n[3,]  163  148\n\ndata=list(r.rep = r.rep, n.rep = n.rep,theta.mle= -0.753)\n\n\nlibrary(R2jags)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"thetaA\",\"thetaB\",\"thetaC\",\"thetaD\"), n.chain=2, n.iter=5000, n.thin=1, n.burn=100, DIC=FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 7\n   Unobserved stochastic nodes: 7\n   Total graph size: 50\n\nInitializing model\nfit.mcmc <- as.mcmc(fit)\nplot(fit.mcmc)summary(fit.mcmc)\n\nIterations = 101:5000\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 4900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean     SD Naive SE Time-series SE\nthetaA -0.7530 0.3741 0.003779       0.004664\nthetaB -0.7473 0.3711 0.003749       0.004767\nthetaC -0.3171 0.1227 0.001239       0.002252\nthetaD -0.3737 0.2557 0.002583       0.009054\n\n2. Quantiles for each variable:\n\n          2.5%     25%     50%     75%    97.5%\nthetaA -1.4841 -1.0046 -0.7609 -0.5050 -0.01045\nthetaB -1.5069 -0.9924 -0.7388 -0.4951 -0.04037\nthetaC -0.5600 -0.4000 -0.3171 -0.2329 -0.07888\nthetaD -0.8795 -0.5459 -0.3697 -0.2014  0.12704\nmat=as.matrix(as.mcmc(fit))\nboxplot(mat)\nabline(h=0)\n\nlibrary(\"bayesplot\")\nlibrary(\"ggplot2\")\nplot_title <- ggtitle(\"Posterior distributions\",\n                      \"with medians and 95% intervals\")\nmcmc_areas(mat,\n           pars = c(\"thetaA\", \"thetaB\", \"thetaC\", \"thetaD\"),\n           prob = 0.95) + plot_title"},{"path":"class-11-prior-distributions.html","id":"bayes-factor","chapter":"11 Class 11: Prior distributions","heading":"11.1 Bayes factor","text":"Example 11.3  (Paul psychic octopus) 2020 soccer World Cup competition, Paul psychic octopus correctly made 8 8 predictions winner. Let \\(H_0\\) represent hypothesis predictions coincidence, let \\(H_1\\) represent hypothesis Paul psychic ability. specifically, ignore possibility draw assume predictions follow binomial distribution parameter \\(\\theta\\) representing probability correct prediction. wish compare following hypotheses\n\\[\n\\begin{split}\n    &H_0: \\theta=.5\\\\\n    &H_1: \\theta\\sim\\text{Uniform}(.5,1)\n\\end{split}\n\\]particular, notice hypothesis testing problem translated inference problem.","code":"model <- function() { \n  q[1] <- 0.5 # prior probabilities\n  q[2] <- 0.5 \n  \n  theta[1] <- 0.5 # H0\n  theta[2] ~ dunif(0.5, 1) # H1\n\n  r ~ dbin(theta[pick], n) # likelihood\n  pick ~ dcat(q[])\n  psychic <- pick - 1 # 1 if psychic, 0 otherwise\n  }\n\nData <- list(r = 8, n = 8)\nfit <- jags(Data, model = model, param = c(\"theta\",\n    \"psychic\"), n.chain = 2, n.iter = 10000, n.thin = 1,\n    n.burn = 0, DIC = FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 2\n   Total graph size: 9\n\nInitializing model\nprint(fit)\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//Rtmp5yyCFv/model1518d707f84d2.txt\", fit using jags,\n 2 chains, each with 10000 iterations (first 0 discarded)\n n.sims = 20000 iterations saved\n         mu.vect sd.vect  2.5%   25%   50%   75% 97.5%\npsychic    0.983   0.127 1.000 1.000 1.000 1.000 1.000\ntheta[1]   0.500   0.000 0.500 0.500 0.500 0.500 0.500\ntheta[2]   0.900   0.089 0.663 0.857 0.925 0.969 0.997\n          Rhat n.eff\npsychic  1.001 20000\ntheta[1] 1.000     1\ntheta[2] 1.005  1200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\nattach.jags(fit)\nhist(theta[,2])"},{"path":"class-12-information-theory.html","id":"class-12-information-theory","chapter":"12 Class 12: Information Theory","heading":"12 Class 12: Information Theory","text":"Exercise 12.1  (五音不全 - part 1) Wordle popular interactive word game given rise numerous Wordle variants. exercise seeks identify optimal strategies (using information theory) solve Wordle variant constructed just class termed 五音不全. ’s works:set \\(n\\) four character Chinese idioms (成语) randomly selected without replacement according provided probability distribution (roughly proportional publication frequency). idiom mapped four digit signature digit corresponds pinyin tone four characters (neutral tone considered “fifth” tone). goal guess four-digit signature randomly selected idioms. Interactive feedback provided typical Wordle puzzle. start initial four-digit guess, feedback provided indicating digits correct location, digits present wrong location, remaining digits present answer.ultimate goal produce two functions automatically provide subsequent guesses based feedback compare_words function. exercise, follow approach spirit Grant Sanderson’s 3Blue1Brown videos identify optimal initial guess. next assignment asked generate function inputs previous guesses feedback data outputs next guess.Primitive forms functions provided along mock contest. primitive functions swapped replaced prepared functions similar contest run. scores rounds averaged individual smallest average (efficient routine) gifted prize basket 美亞超市 keeping Chinese theme. Shiny simulation demonstrate wordle variant  Comparison functions  Example functions  Mock contest ","code":"\n\nload(\"mydict2.RData\")\n\ncompare_words = function(target_str, guess_str) {\n    if ((nchar(target_str) != 4) | (nchar(guess_str) != 4)) {\n        stop(\"target and guess string must be length 4.\")\n    }\n\n    target = strsplit(target_str, \"\")[[1]]\n    guess = strsplit(guess_str, \"\")[[1]]\n    result = character(nchar(guess_str))\n\n    for (i in 1:4) {\n        if (guess[i] == target[i]) {\n            result[i] = \"correct\"\n            target[i] = \"\"\n            guess[i] = \"\"\n        }\n    }\n    for (i in 1:4) {\n        if (guess[i] != \"\") {\n            if (is.element(guess[i], target)) {\n                result[i] = \"in-word\"\n                target[which(target == guess[i])[1]] = \"\"\n                next\n            }\n            result[i] = \"not-in-word\"\n        }\n    }\n    result\n}\n\ncheck_words = function(target_str, guess_str) {\n    compare_result = compare_words(target_str, guess_str)\n    result = \"keep guessing\"\n    if (all(compare_result == \"correct\")) {\n        result = \"solved\"\n    }\n    result\n}\nf.init1 = function(word_num, score, words) {\n    \"1234\"\n}\nf.init2 = function(word_num, score, words) {\n    \"1324\"\n}\nf.init3 = function(word_num, score, words) {\n    \"1243\"\n}\nf.init4 = function(word_num, score, words) {\n    \"1233\"\n}\nf.init5 = function(word_num, score, words) {\n    \"1142\"\n}\n\n\nf.main1 = function(word_num, scores.current, words, guess_number,\n    myguesses, myfeedback) {\n\n    correct = rep(as.character(NA), 4)\n    chars = NA\n\n    mymat = matrix(\"maybe\", nrow = 5, ncol = 4)\n    rownames(mymat) = as.character(1:5)\n    colnames(mymat) = as.character(1:4)\n\n    for (i in 1:guess_number) {\n        nums = strsplit(myguesses[i], \"\")[[1]]\n        pos = myfeedback[i, ]\n\n        cor = which(pos == \"correct\")\n        iw = which(pos == \"in-word\")\n\n        niw = setdiff(unique(nums[pos == \"not-in-word\"]), c(nums[cor],\n            nums[iw]))\n        niw2 = intersect(c(nums[cor], nums[iw]), unique(nums[pos ==\n            \"not-in-word\"]))\n\n        if (length(niw2) > 0) {\n            for (j in 1:length(niw2)) {\n                mymat[niw2[j], which(pos == \"not-in-word\" & nums ==\n                  niw2[j])[1]] = \"no\"\n            }\n        }\n\n        if (length(niw) > 0) {\n            for (j in 1:length(niw)) {\n                mymat[niw[j], ] = \"no\"\n            }\n        }\n\n        if (length(cor) > 0) {\n            correct[cor] = nums[cor]\n            if (sum(is.na(chars)) > 0) {\n                chars = nums[cor]\n            } else {\n                chars = append(chars, nums[cor])\n            }\n            for (j in 1:length(cor)) {\n                mymat[, cor[j]] = \"no\"\n                mymat[nums[cor[j]], cor[j]] = \"yes\"\n            }\n        }\n\n        if (length(iw) > 0) {\n            if (sum(is.na(chars)) > 0) {\n                chars = nums[iw]\n            } else {\n                chars = append(chars, nums[iw])\n            }\n\n            for (j in 1:length(iw)) {\n                mymat[nums[iw[j]], iw[j]] = \"no\"\n            }\n        }\n\n        chars = setdiff(chars, correct)\n\n    }  #end of i loop \n\n    chars.og = chars\n    mymat.og = mymat\n    done = FALSE\n\n    while (!done) {\n        mymat = mymat.og\n        chars = chars.og\n        out = correct\n        ind = which(is.na(correct))\n\n        if (length(ind) > 0) {\n            for (j in 1:length(ind)) {\n\n                if (length(chars) == 0) {\n                  mypos = which(is.na(out))[1]\n                  mynum = as.character(which(mymat[, mypos] ==\n                    \"maybe\"))[1]\n                  out[mypos] = mynum\n                  mymat[, mypos] = \"X\"\n                }\n\n                if (length(chars) > 0) {\n                  n.maybe = sum(mymat[chars[1], ] == \"maybe\")\n                  if (n.maybe > 0) {\n                    mypos = sample(as.character(which(mymat[chars[1],\n                      ] == \"maybe\")), 1)\n                    out[as.numeric(mypos)] = chars[1]\n                    mymat[, as.numeric(mypos)] = \"X\"\n                    chars = setdiff(chars, chars[1])\n                  }\n                }\n\n            }\n        }\n\n        if (sum(!is.na(out)) == 4) {\n            done = TRUE\n        }\n    }  #end of while  \n\n    paste(out, collapse = \"\")\n\n}\n\nf.main2 = f.main3 = f.main4 = f.main5 = f.main1myseed = 31428212  # seed will be changed for competition\nset.seed(myseed)\nn = 1000\ncomp_words = mydict[sample(1:dim(mydict)[1], n, prob = mydict$freq,\n    replace = FALSE), \"sig\"]\nguesses = array(as.character(NA), dim = c(n, 10, 5))\nfeedback = array(as.character(NA), dim = c(n, 10, 4, 5))\nscores = matrix(0, nrow = n, ncol = 5)\n\nfor (word_num in 1:n) {\n    words = if (word_num == 1) {\n        NA\n    } else {\n        words = comp_words[1:(word_num - 1)]\n    }\n    scores.current = apply(matrix(scores[1:word_num, ], ncol = 5),\n        2, sum)\n\n    for (i in 1:5) {\n        guess_number = 1\n        f.init = get(paste0(\"f.init\", i))\n        guess = f.init(word_num, scores.current, words)\n        guesses[word_num, 1, i] = guess\n        res = check_words(comp_words[word_num], guess)\n        feedback[word_num, guess_number, , i] = compare_words(comp_words[word_num],\n            guess)\n\n        while (res == \"keep guessing\" & guess_number <= 9) {\n            myguesses = guesses[word_num, 1:guess_number, i]\n            myfeedback = matrix(feedback[word_num, 1:guess_number,\n                , i], nrow = guess_number, ncol = 4)\n            f.main = get(paste0(\"f.main\", i))\n            guess = f.main(word_num, scores.current, words, guess_number,\n                myguesses, myfeedback)\n            guess_number = guess_number + 1\n            guesses[word_num, guess_number, i] = guess\n            res = check_words(comp_words[word_num], guess)\n            feedback[word_num, guess_number, , i] = compare_words(comp_words[word_num],\n                guess)\n            res\n        }\n\n        scores[word_num, i] = guess_number\n    }\n\n}\n\napply(scores, 2, mean)\n[1] 2.879 2.822 2.878 3.452 3.203"},{"path":"class-13-information-theory-cont.html","id":"class-13-information-theory-cont","chapter":"13 Class 13: Information Theory (cont)","heading":"13 Class 13: Information Theory (cont)","text":"Exercise 13.1  (五音不全 - part 2) continuation previous exercise, generate function inputs previous guesses feedback data outputs next guess. Example inputs outputs provided. two finally submitted functions able smoothly run mock contest previously provided. Sample input output f.init function  Sample input output f.main function ","code":"word_num\n[1] 5\nscores.current\n[1] 14 12 15 17 11\nwords\n[1] \"4244\" \"2224\" \"4324\" \"3511\"\nf.init(word_num, scores.current, words)\n[1] \"1142\"word_num\n[1] 5\nscores.current\n[1] 14 12 15 17 11\nwords\n[1] \"4244\" \"2224\" \"4324\" \"3511\"\nguess_number\n[1] 3\nmyguesses\n[1] \"1142\" \"4211\"\nmyfeedback\n     [,1]      [,2]          [,3]          [,4]     \n[1,] \"in-word\" \"not-in-word\" \"in-word\"     \"in-word\"\n[2,] \"correct\" \"correct\"     \"not-in-word\" \"correct\"\n\nf.main(word_num, scores.current, words, guess_number, myguesses,\n    myfeedback)\n[1] \"4221\"\n\ncheck_words(comp_words[word_num], \"4221\")\n[1] \"solved\""},{"path":"class-14-hierarchical-models.html","id":"class-14-hierarchical-models","chapter":"14 Class 14: Hierarchical Models","heading":"14 Class 14: Hierarchical Models","text":"","code":""},{"path":"class-14-hierarchical-models.html","id":"example-1-bristol-babies","chapter":"14 Class 14: Hierarchical Models","heading":"14.1 Example 1: Bristol babies","text":"Example 14.1  (Bristol babies) [Bristol heart scandal](https://en.wikipedia.org/wiki/Bristol_heart_scandal came discovered babies dying high rates cardiac surgery treated Bristol Royal Infirmary. comprehensive report7 subsequently led substantial changes health service monitoring UK. Data incident statistically analyzed in8 ,9 includes table . following models fit:constant-risk model\n\\[\n\\begin{split}\nX_i&\\sim\\text{Binomial}(n_i,\\theta)\\\\\n\\theta&\\sim\\text{Uniform}(0,1)\n\\end{split}\n\\]independent parameters model\n\\[\n\\begin{split}\nX_i&\\sim\\text{Binomial}(n_i,\\theta_i)\\\\\n\\theta_i&\\sim\\text{Uniform}(0,1)\n\\end{split}\n\\]hierarchical model\n\\[\n\\begin{split}\nX_i&\\sim\\text{Binomial}(n_i,\\theta_i)\\\\\n\\text{logit_i}(\\theta)&\\sim \\mathcal{N}(\\mu,\\sigma^2)\\\\\n\\mu&\\sim\\text{Uniform}(-100,100)\\\\\n1/\\sigma^2&\\sim\\text{Uniform}(0,100)\n\\end{split}\n\\]\nResidual analysis constant-risk model shows poor model selection. Shrinkage observed parameters hierarchical model.","code":"\nlibrary(tidyverse)\nlibrary(kableExtra)\nbristol = data.frame(hospital = c(\"Bristol\", \"Leicester\", \"Leeds\",\n    \"Oxford\", \"Guys\", \"Liverpool\", \"Southampton\", \"Great Ormond St\",\n    \"Newcastle\", \"Harefield\", \"Birmingham\", \"Brompton\"), operations = c(143,\n    187, 323, 122, 164, 405, 239, 482, 195, 177, 581, 301), deaths = c(41,\n    25, 24, 23, 25, 42, 24, 53, 26, 25, 58, 31)) %>%\n    mutate(mortality = deaths/operations) %>%\n    arrange(desc(mortality))\n\n# xtable(bristol,digits=c(0,0,0,0,2))\n\nkbl(bristol) %>%\n    kable_classic_2(full_width = F)"},{"path":"class-14-hierarchical-models.html","id":"constant-risk-model","chapter":"14 Class 14: Hierarchical Models","heading":"14.1.1 Constant-risk model","text":"","code":"model = function() {\n\n    ## Likelihood\n    for (i in 1:12) {\n        y[i] ~ dbin(theta, n[i])\n        res[i] <- (y[i] - n[i] * theta)/sqrt(n[i] * theta * (1 -\n            theta))\n        res2[i] <- res[i] * res[i]\n    }\n\n    ## prior\n    theta ~ dunif(0, 1)\n    X2.obs <- sum(res2[])\n\n}\n\n\ndata = list(n = bristol$operations, y = bristol$deaths)\n\nlibrary(R2jags)\nfit <- jags(data = data, model = model, parameters.to.save = c(\"theta\",\n    \"res\", \"X2.obs\"), n.chain = 2, n.iter = 5000, n.thin = 1,\n    n.burn = 100, DIC = FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 12\n   Unobserved stochastic nodes: 1\n   Total graph size: 102\n\nInitializing model\nfit.mcmc <- as.mcmc(fit)\nsummary(fit.mcmc)\n\nIterations = 101:5000\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 4900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean       SD  Naive SE Time-series SE\nres[1]   6.1499 0.329142 0.0033248      4.275e-03\nres[10] -0.9222 0.246955 0.0024946      3.209e-03\nres[11] -1.4817 0.384158 0.0038806      4.992e-03\nres[12] -2.5181 0.257998 0.0026062      3.353e-03\nres[2]   2.3392 0.236772 0.0023918      3.076e-03\nres[3]   1.2884 0.245869 0.0024836      3.194e-03\nres[4]   0.8796 0.246193 0.0024869      3.199e-03\nres[5]   0.5859 0.246649 0.0024915      3.205e-03\nres[6]   0.5830 0.251561 0.0025411      3.268e-03\nres[7]  -0.6644 0.363689 0.0036738      4.726e-03\nres[8]  -0.9968 0.325572 0.0032888      4.230e-03\nres[9]  -0.8975 0.279907 0.0028275      3.637e-03\ntheta    0.1199 0.005574 0.0000563      7.253e-05\nX2.obs  59.0388 2.764042 0.0279210      3.679e-02\n\n2. Quantiles for each variable:\n\n           2.5%     25%     50%     75%    97.5%\nres[1]   5.5309  5.9250  6.1440  6.3703  6.80791\nres[10] -1.3919 -1.0900 -0.9248 -0.7557 -0.43395\nres[11] -2.2125 -1.7428 -1.4857 -1.2227 -0.72224\nres[12] -3.0102 -2.6931 -2.5202 -2.3438 -2.00949\nres[2]   1.8919  2.1778  2.3357  2.4982  2.81052\nres[3]   0.8229  1.1210  1.2852  1.4537  1.77674\nres[4]   0.4131  0.7120  0.8765  1.0452  1.36818\nres[5]   0.1182  0.4181  0.5829  0.7519  1.07509\nres[6]   0.1060  0.4118  0.5799  0.7523  1.08189\nres[7]  -1.3555 -0.9116 -0.6684 -0.4194  0.05536\nres[8]  -1.6159 -1.2181 -1.0002 -0.7774 -0.35289\nres[9]  -1.4298 -1.0877 -0.9004 -0.7088 -0.34393\ntheta    0.1092  0.1161  0.1198  0.1236  0.13077\nX2.obs  56.7590 57.0736 58.0523 60.0141 66.59561\nmat=as.matrix(as.mcmc(fit))\ntheta.avg=mean(mat[,\"theta\"])\nboxplot(mat[,paste0(\"res[\",1:12,\"]\")])\nabline(h=0)\n\nlibrary(\"bayesplot\")\nlibrary(\"ggplot2\")\nplot_title <- ggtitle(\"Posterior distributions  of residuals\",\n                      \"with medians and 95% intervals\")\nmcmc_areas(mat,\n           pars = paste0(\"res[\",1:12,\"]\"),\n           prob = 0.95) + plot_title"},{"path":"class-14-hierarchical-models.html","id":"independent-parameters-model","chapter":"14 Class 14: Hierarchical Models","heading":"14.1.2 Independent-parameters model","text":"","code":"model = function() {\n\n    ## Likelihood\n    for (i in 1:12) {\n        y[i] ~ dbin(theta[i], n[i])\n    }\n\n    ## priors\n    for (i in 1:12) {\n        theta[i] ~ dunif(0, 1)\n    }\n}\n\n\ndata = list(n = bristol$operations, y = bristol$deaths)\n\nfit <- jags(data = data, model = model, parameters.to.save = c(\"theta\"),\n    n.chain = 2, n.iter = 5000, n.thin = 1, n.burn = 100, DIC = FALSE)\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 12\n   Unobserved stochastic nodes: 12\n   Total graph size: 38\n\nInitializing model\nfit.mcmc <- as.mcmc(fit)\nsummary(fit.mcmc)\n\nIterations = 101:5000\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 4900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean      SD  Naive SE Time-series SE\ntheta[1]  0.28964 0.03750 0.0003788      0.0004795\ntheta[10] 0.10412 0.01983 0.0002004      0.0002510\ntheta[11] 0.10153 0.01264 0.0001277      0.0001647\ntheta[12] 0.07702 0.01484 0.0001499      0.0001984\ntheta[2]  0.19362 0.03521 0.0003557      0.0004463\ntheta[3]  0.15707 0.02807 0.0002836      0.0003602\ntheta[4]  0.14576 0.02647 0.0002674      0.0003341\ntheta[5]  0.13724 0.02476 0.0002501      0.0003207\ntheta[6]  0.13719 0.02426 0.0002451      0.0003026\ntheta[7]  0.11155 0.01438 0.0001452      0.0001784\ntheta[8]  0.10582 0.01518 0.0001533      0.0001856\ntheta[9]  0.10571 0.01731 0.0001749      0.0002253\n\n2. Quantiles for each variable:\n\n             2.5%     25%     50%     75%  97.5%\ntheta[1]  0.21849 0.26348 0.28889 0.31486 0.3648\ntheta[10] 0.06844 0.08992 0.10300 0.11692 0.1452\ntheta[11] 0.07819 0.09279 0.10081 0.10985 0.1277\ntheta[12] 0.05004 0.06676 0.07615 0.08638 0.1084\ntheta[2]  0.12915 0.16876 0.19118 0.21676 0.2668\ntheta[3]  0.10638 0.13730 0.15578 0.17537 0.2154\ntheta[4]  0.09786 0.12732 0.14413 0.16325 0.2013\ntheta[5]  0.09274 0.11992 0.13583 0.15317 0.1899\ntheta[6]  0.09294 0.12013 0.13596 0.15311 0.1885\ntheta[7]  0.08494 0.10161 0.11087 0.12091 0.1411\ntheta[8]  0.07796 0.09523 0.10536 0.11565 0.1369\ntheta[9]  0.07422 0.09363 0.10484 0.11682 0.1420\nmat=as.matrix(as.mcmc(fit))\n\nmat.ind=mat[,paste0(\"theta[\",1:12,\"]\")]\n\nplot_title <- ggtitle(\"Posterior distributions of thetas\",\n                      \"with medians and 95% intervals\")\nmcmc_areas(mat,\n           pars = paste0(\"theta[\",1:12,\"]\"),\n           prob = 0.95) + plot_title"},{"path":"class-14-hierarchical-models.html","id":"hierarchical-model","chapter":"14 Class 14: Hierarchical Models","heading":"14.1.3 Hierarchical model","text":"","code":"model = function() {\n\n    ## Likelihood\n    for (i in 1:12) {\n        y[i] ~ dbin(theta[i], n[i])\n        logit(theta[i]) <- logit.theta[i]\n        logit.theta[i] ~ dnorm(mu, inv.sigma.squared)\n    }\n\n    ## priors\n    inv.sigma.squared <- 1/pow(sigma, 2)\n    sigma ~ dunif(0, 100)\n    mu ~ dunif(-100, 100)\n}\n\n\ndata = list(n = bristol$operations, y = bristol$deaths)\n\nfit <- jags(data = data, model = model, parameters.to.save = c(\"theta\",\n    \"mu\", \"sigma\"), n.chain = 2, n.iter = 5000, n.thin = 1, n.burn = 100,\n    DIC = FALSE)\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 12\n   Unobserved stochastic nodes: 14\n   Total graph size: 57\n\nInitializing model\nfit.mcmc <- as.mcmc(fit)\nsummary(fit.mcmc)\n\nIterations = 101:5000\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 4900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean      SD  Naive SE Time-series SE\nmu        -1.9309 0.14106 0.0014249      0.0018997\nsigma      0.4267 0.13195 0.0013329      0.0027037\ntheta[1]   0.2496 0.03701 0.0003738      0.0006270\ntheta[10]  0.1064 0.01787 0.0001805      0.0002226\ntheta[11]  0.1026 0.01216 0.0001229      0.0001658\ntheta[12]  0.0842 0.01455 0.0001469      0.0002097\ntheta[2]   0.1706 0.03012 0.0003043      0.0004233\ntheta[3]   0.1462 0.02427 0.0002452      0.0003174\ntheta[4]   0.1376 0.02296 0.0002319      0.0002905\ntheta[5]   0.1325 0.02208 0.0002230      0.0002816\ntheta[6]   0.1325 0.02183 0.0002205      0.0002934\ntheta[7]   0.1123 0.01355 0.0001368      0.0001707\ntheta[8]   0.1072 0.01433 0.0001447      0.0001817\ntheta[9]   0.1073 0.01641 0.0001658      0.0002192\n\n2. Quantiles for each variable:\n\n              2.5%      25%      50%     75%   97.5%\nmu        -2.20675 -2.01880 -1.93144 -1.8430 -1.6404\nsigma      0.22923  0.33369  0.40612  0.4949  0.7390\ntheta[1]   0.18085  0.22344  0.24890  0.2739  0.3248\ntheta[10]  0.07354  0.09376  0.10572  0.1179  0.1436\ntheta[11]  0.07990  0.09428  0.10233  0.1108  0.1271\ntheta[12]  0.05739  0.07400  0.08348  0.0935  0.1146\ntheta[2]   0.11831  0.14911  0.16852  0.1895  0.2361\ntheta[3]   0.10274  0.12908  0.14512  0.1617  0.1969\ntheta[4]   0.09650  0.12162  0.13623  0.1522  0.1865\ntheta[5]   0.09314  0.11694  0.13132  0.1469  0.1797\ntheta[6]   0.09328  0.11738  0.13131  0.1462  0.1791\ntheta[7]   0.08697  0.10293  0.11178  0.1214  0.1398\ntheta[8]   0.08073  0.09723  0.10653  0.1165  0.1368\ntheta[9]   0.07744  0.09571  0.10644  0.1181  0.1416\nmat=as.matrix(as.mcmc(fit))\n\nmat.hier=mat[,paste0(\"theta[\",1:12,\"]\")]\n\nplot_title <- ggtitle(\"Posterior distributions of thetas\",\n                      \"with medians and 95% intervals\")\nmcmc_areas(mat,\n           pars = paste0(\"theta[\",1:12,\"]\"),\n           prob = 0.95) + plot_titlelibrary(reshape2)\ndf1 = melt(mat.ind) %>%\n    mutate(model = \"independent\")\ndf2 = melt(mat.hier) %>%\n    mutate(model = \"hierarchical\")\ndf = bind_rows(df1, df2)\ndf$hospital = c(\"Bristol\", \"Leicester\", \"Leeds\", \"Oxford\", \"Guys\",\n    \"Liverpool\", \"Southampton\", \"Great Ormond St\", \"Newcastle\",\n    \"Harefield\", \"Birmingham\", \"Brompton\")[as.numeric(as.factor(df$Var2))]\n\nlibrary(tidyverse)\nlibrary(hrbrthemes)\nlibrary(viridis)\nlibrary(ggridges)\n\ndf %>%\n    ggplot(aes(y = hospital, x = value, fill = model)) + geom_density_ridges(alpha = 0.6) +\n    scale_fill_viridis(discrete = TRUE) + scale_color_viridis(discrete = TRUE) +\n    theme_ipsum() + theme(panel.spacing = unit(0.1, \"lines\"),\n    strip.text.x = element_text(size = 8)) + xlab(\"\") + ylab(\"Posterior Distributions\") +\n    geom_vline(xintercept = theta.avg, linetype = \"dotted\", color = \"blue\",\n        size = 1.5)\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2\n3.4.0.\nℹ Please use `linewidth` instead.\nPicking joint bandwidth of 0.00308"},{"path":"class-14-hierarchical-models.html","id":"example-2-james-stein-baseball","chapter":"14 Class 14: Hierarchical Models","heading":"14.2 Example 2: James-Stein Baseball","text":"Example 14.2  (James-Stein baseball) See vignette details example. James-Stein baseball data10 analyzed using stan_glm rstanarm package. includes model fits complete pooling (constant-risk model), pooling (independent-parameter model), partial pooling (hierarchical model).","code":"library(rstanarm)\nLoading required package: Rcpp\nThis is rstanarm version 2.21.3\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n  options(mc.cores = parallel::detectCores())\ndata(bball1970)\nbball <- bball1970\n\n# xtable(bball)\n\nkbl(bball) %>%\n    kable_classic_2(full_width = F)\nN <- nrow(bball)\nK <- bball$AB\ny <- bball$Hits\nK_new <- bball$RemainingAB\ny_new <- bball$RemainingHits\n\nbatting_avg <- function(x) print(format(round(x, digits = 3),\n    nsmall = 3), quote = FALSE)\nplayer_avgs <- y/K  # player avgs through 45 AB\ntot_avg <- sum(y)/sum(K)  # overall avg through 45 AB\n\ncat(\"Player averages through 45 at-bats:\\n\")\nPlayer averages through 45 at-bats:\nbatting_avg(player_avgs)\n [1] 0.400 0.378 0.356 0.333 0.311 0.311 0.289 0.267 0.244\n[10] 0.244 0.222 0.222 0.222 0.222 0.222 0.200 0.178 0.156\ncat(\"Overall average through 45 at-bats:\\n\")\nOverall average through 45 at-bats:\nbatting_avg(tot_avg)\n[1] 0.265"},{"path":"class-14-hierarchical-models.html","id":"complete-pooling","chapter":"14 Class 14: Hierarchical Models","heading":"14.2.1 Complete pooling","text":"","code":"SEED <- 202\nwi_prior <- normal(-1, 1)  # weakly informative prior on log-odds\nfit_pool <- stan_glm(cbind(Hits, AB - Hits) ~ 1, data = bball, family = binomial(\"logit\"),\n                     prior_intercept = wi_prior, seed = SEED)\n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.2e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.015257 seconds (Warm-up)\nChain 1:                0.018122 seconds (Sampling)\nChain 1:                0.033379 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.015807 seconds (Warm-up)\nChain 2:                0.017317 seconds (Sampling)\nChain 2:                0.033124 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.015199 seconds (Warm-up)\nChain 3:                0.018457 seconds (Sampling)\nChain 3:                0.033656 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.01666 seconds (Warm-up)\nChain 4:                0.018921 seconds (Sampling)\nChain 4:                0.035581 seconds (Total)\nChain 4: \n\ninvlogit <- plogis  # function(x) 1/(1 + exp(-x))\nsummary_stats <- function(posterior) {\n  x <- invlogit(posterior)  # log-odds -> probabilities\n  t(apply(x, 2, quantile, probs = c(0.1, 0.5, 0.9))) \n}\n\npool <- summary_stats(as.matrix(fit_pool))  # as.matrix extracts the posterior draws\npool <- matrix(pool,  # replicate to give each player the same estimates\n               nrow(bball), ncol(pool), byrow = TRUE, \n               dimnames = list(bball$Player, c(\"10%\", \"50%\", \"90%\")))\nbatting_avg(pool)\n           10%   50%   90%  \nClemente   0.246 0.265 0.286\nRobinson   0.246 0.265 0.286\nHoward     0.246 0.265 0.286\nJohnstone  0.246 0.265 0.286\nBerry      0.246 0.265 0.286\nSpencer    0.246 0.265 0.286\nKessinger  0.246 0.265 0.286\nAlvarado   0.246 0.265 0.286\nSanto      0.246 0.265 0.286\nSwaboda    0.246 0.265 0.286\nPetrocelli 0.246 0.265 0.286\nRodriguez  0.246 0.265 0.286\nScott      0.246 0.265 0.286\nUnser      0.246 0.265 0.286\nWilliams   0.246 0.265 0.286\nCampaneris 0.246 0.265 0.286\nMunson     0.246 0.265 0.286\nAlvis      0.246 0.265 0.286\n\ninvlogit <- plogis  # function(x) 1/(1 + exp(-x))\nsummary_stats <- function(posterior) {\n  x <- invlogit(posterior)  # log-odds -> probabilities\n  t(apply(x, 2, quantile, probs = c(0.1, 0.5, 0.9)))\n}\n\npool <- summary_stats(as.matrix(fit_pool))  # as.matrix extracts the posterior draws\npool <- matrix(pool,  # replicate to give each player the same estimates\n               nrow(bball), ncol(pool), byrow = TRUE,\n               dimnames = list(bball$Player, c(\"10%\", \"50%\", \"90%\")))\nbatting_avg(pool)\n           10%   50%   90%  \nClemente   0.246 0.265 0.286\nRobinson   0.246 0.265 0.286\nHoward     0.246 0.265 0.286\nJohnstone  0.246 0.265 0.286\nBerry      0.246 0.265 0.286\nSpencer    0.246 0.265 0.286\nKessinger  0.246 0.265 0.286\nAlvarado   0.246 0.265 0.286\nSanto      0.246 0.265 0.286\nSwaboda    0.246 0.265 0.286\nPetrocelli 0.246 0.265 0.286\nRodriguez  0.246 0.265 0.286\nScott      0.246 0.265 0.286\nUnser      0.246 0.265 0.286\nWilliams   0.246 0.265 0.286\nCampaneris 0.246 0.265 0.286\nMunson     0.246 0.265 0.286\nAlvis      0.246 0.265 0.286"},{"path":"class-14-hierarchical-models.html","id":"no-pooling","chapter":"14 Class 14: Hierarchical Models","heading":"14.2.2 No pooling","text":"","code":"fit_nopool <- update(fit_pool, formula = . ~ 0 + Player, prior = wi_prior)\n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.069053 seconds (Warm-up)\nChain 1:                0.080344 seconds (Sampling)\nChain 1:                0.149397 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.067713 seconds (Warm-up)\nChain 2:                0.076083 seconds (Sampling)\nChain 2:                0.143796 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.064684 seconds (Warm-up)\nChain 3:                0.074064 seconds (Sampling)\nChain 3:                0.138748 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.068065 seconds (Warm-up)\nChain 4:                0.08149 seconds (Sampling)\nChain 4:                0.149555 seconds (Total)\nChain 4: \nnopool <- summary_stats(as.matrix(fit_nopool))\nrownames(nopool) <- as.character(bball$Player)\nbatting_avg(nopool)\n            \nparameters   10%   50%   90%  \n  Clemente   0.297 0.386 0.484\n  Robinson   0.281 0.365 0.456\n  Howard     0.265 0.345 0.434\n  Johnstone  0.242 0.325 0.418\n  Berry      0.226 0.306 0.390\n  Spencer    0.225 0.304 0.391\n  Kessinger  0.207 0.284 0.371\n  Alvarado   0.188 0.265 0.353\n  Santo      0.175 0.246 0.328\n  Swaboda    0.175 0.245 0.327\n  Petrocelli 0.154 0.223 0.304\n  Rodriguez  0.155 0.224 0.303\n  Scott      0.159 0.223 0.303\n  Unser      0.153 0.224 0.307\n  Williams   0.156 0.224 0.304\n  Campaneris 0.138 0.204 0.284\n  Munson     0.124 0.185 0.260\n  Alvis      0.107 0.164 0.241"},{"path":"class-14-hierarchical-models.html","id":"partial-pooling","chapter":"14 Class 14: Hierarchical Models","heading":"14.2.3 Partial pooling","text":"","code":"fit_partialpool <- stan_glmer(cbind(Hits, AB - Hits) ~ (1 | Player),\n    data = bball, family = binomial(\"logit\"), prior_intercept = wi_prior,\n    seed = SEED)\n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.119321 seconds (Warm-up)\nChain 1:                0.125259 seconds (Sampling)\nChain 1:                0.24458 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 9e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.141288 seconds (Warm-up)\nChain 2:                0.106701 seconds (Sampling)\nChain 2:                0.247989 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 6e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.133025 seconds (Warm-up)\nChain 3:                0.143619 seconds (Sampling)\nChain 3:                0.276644 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'binomial' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 9e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.116647 seconds (Warm-up)\nChain 4:                0.084232 seconds (Sampling)\nChain 4:                0.200879 seconds (Total)\nChain 4: \n\n\n# shift each player's estimate by intercept (and then drop\n# intercept)\nshift_draws <- function(draws) {\n    sweep(draws[, -1], MARGIN = 1, STATS = draws[, 1], FUN = \"+\")\n}\nalphas <- shift_draws(as.matrix(fit_partialpool))\npartialpool <- summary_stats(alphas)\npartialpool <- partialpool[-nrow(partialpool), ]\nrownames(partialpool) <- as.character(bball$Player)\nbatting_avg(partialpool)\n            \nparameters   10%   50%   90%  \n  Clemente   0.249 0.283 0.349\n  Robinson   0.246 0.281 0.341\n  Howard     0.243 0.277 0.332\n  Johnstone  0.239 0.274 0.324\n  Berry      0.237 0.271 0.317\n  Spencer    0.238 0.271 0.317\n  Kessinger  0.232 0.267 0.309\n  Alvarado   0.226 0.265 0.303\n  Santo      0.222 0.261 0.298\n  Swaboda    0.221 0.261 0.301\n  Petrocelli 0.217 0.258 0.293\n  Rodriguez  0.215 0.258 0.294\n  Scott      0.217 0.259 0.294\n  Unser      0.214 0.258 0.295\n  Williams   0.215 0.258 0.295\n  Campaneris 0.210 0.255 0.292\n  Munson     0.204 0.252 0.287\n  Alvis      0.195 0.249 0.284"},{"path":"class-14-hierarchical-models.html","id":"observed-vs-estimated","chapter":"14 Class 14: Hierarchical Models","heading":"14.2.4 Observed vs estimated","text":"Exercise 14.1  (Rat tumors) (Tarone, 1982)11 provides data set tumor incidence historical control groups rats; specifically endometrial stromal polyps female lab rats type F344 analyzed (Gelman, 2021)12. dataset can accessed loaded R rstanarm package usingFit hierarchical Bayesian model data reproduce Figure 5.4 page 113 (Gelman, 2021)13.","code":"library(ggplot2)\nmodels <- c(\"complete pooling\", \"no pooling\", \"partial pooling\")\nestimates <- rbind(pool, nopool, partialpool)\ncolnames(estimates) <- c(\"lb\", \"median\", \"ub\")\nplotdata <- data.frame(estimates, observed = rep(player_avgs,\n    times = length(models)), model = rep(models, each = N), row.names = NULL)\n\nggplot(plotdata, aes(x = observed, y = median, ymin = lb, ymax = ub)) +\n    geom_hline(yintercept = tot_avg, color = \"lightpink\", size = 0.75) +\n    geom_abline(intercept = 0, slope = 1, color = \"skyblue\") +\n    geom_linerange(color = \"gray60\", size = 0.75) + geom_point(size = 2.5,\n    shape = 21, fill = \"gray30\", color = \"white\", stroke = 0.2) +\n    facet_grid(. ~ model) + coord_fixed() + scale_x_continuous(breaks = c(0.2,\n    0.3, 0.4)) + labs(x = \"Observed Hits / AB\", y = \"Predicted chance of hit\") +\n    ggtitle(\"Posterior Medians and 80% Intervals\")\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2\n3.4.0.\nℹ Please use `linewidth` instead.\ndata(tumors, package = \"rstanarm\")"},{"path":"class-14-hierarchical-models.html","id":"example-3-chatgpt","chapter":"14 Class 14: Hierarchical Models","heading":"14.3 Example 3: ChatGPT","text":"Example 14.3  (ChatGPT Hierarchical model) ChatGPT: stan code hierarchical model.Sure! example hierarchical model Stan. model assumes set data points, y, come different groups, want model variation data within group variation group means across groups.code generate pink heart shape white background using ggplot2 package. can adjust size, color, background heart shape liking.","code":"\nlibrary(prettycode)\nstan_code <- \"\ndata {\n  int<lower=1> N;  // number of observations\n  int<lower=1> K;  // number of groups\n  int<lower=1, upper=K> group[N];  // group indicator for each observation\n  real y[N];  // observed data\n}\n\nparameters {\n  real mu0;             // prior mean for group means\n  real<lower=0> sigma0;  // prior std. dev. for group means\n  real<lower=0> sigma;   // std. dev. of the observations within each group\n  vector[K] mu;          // group means\n}\n\nmodel {\n  // Priors\n  mu ~ normal(mu0, sigma0);  // prior for group means\n  sigma ~ cauchy(0, 1);      // weakly informative prior for sigma\n\n  // Likelihood\n  for (i in 1:N) {\n    y[i] ~ normal(mu[group[i]], sigma);\n  }\n}\n\"\nstan_pretty(stan_code, highlight=TRUE)"},{"path":"to-be-incorporated.html","id":"to-be-incorporated","chapter":"15 To Be Incorporated","heading":"15 To Be Incorporated","text":"","code":""},{"path":"to-be-incorporated.html","id":"jags","chapter":"15 To Be Incorporated","heading":"15.1 JAGS","text":"","code":"library(R2jags)\nLoading required package: rjags\nLoading required package: coda\nLinked to JAGS 4.3.0\nLoaded modules: basemod,bugs\n\nAttaching package: 'R2jags'\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nmymodel= function(){\nfor ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\nn <- 50\ntheta.true <- .3\ny.sim <- rbinom(n, 1, theta.true)\n\nmydata = list(    \n  y = y.sim ,\n  Ntotal = n \n)\n\n\n\nfit <- jags(data=mydata, model=mymodel, parameters.to.save = c(\"theta\"), n.chain=2, n.iter=200, n.thin=1, n.burn=100)\nmodule glm loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmphaFY5e/model12f5f37eb986b.txt\", fit using jags,\n 2 chains, each with 200 iterations (first 100 discarded)\n n.sims = 200 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%\ntheta      0.325   0.062  0.201  0.284  0.329  0.369  0.433\ndeviance  63.604   1.244 62.688 62.799 63.201 63.903 66.765\n          Rhat n.eff\ntheta    1.045    82\ndeviance 1.132    47\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 0.8 and DIC = 64.4\nDIC is an estimate of expected predictive error (lower deviance is better).library(R2jags)\n\nmodel= function(){\nM ~ dcat(p1)\n# sampling distribution is uniform over first N integers\n# use step function to change p1[j] to 0 for j>N\nfor (j in 1:1000) {\np1[j] <- step(N - j + 0.01)/N\n}\nN ~ dcat(p2)\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\ndata=list(\"M\"=100)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"N\",\"M\"), n.chain=2, n.iter=100, n.thin=1, n.burn=0, DIC=FALSE)\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 1\n   Total graph size: 7007\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmphaFY5e/model12f5f261fc56b.txt\", fit using jags,\n 2 chains, each with 100 iterations (first 0 discarded)\n n.sims = 200 iterations saved\n  mu.vect sd.vect    2.5%    25% 50%    75%   97.5%  Rhat\nM  100.00   0.000 100.000 100.00 100 100.00 100.000 1.000\nN  259.14 199.757 102.975 130.75 182 292.25 856.125 0.996\n  n.eff\nM     1\nN   200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).library(rjags)\nmodel_string <- \"\nmodel {\nM ~ dcat(p1)\nfor (j in 1:1000) {\np1[j] <- (pow(j*step(N - j + 0.01)/N,2)-pow((j-1)*step(N - j  + 0.01)/N,2))\n}\nN ~ dcat(p2[])\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\"\n\ndata=list(\"M\"=50)\njmodel <- jags.model(textConnection(model_string), data = data,inits=list(N=100),n.chains = 2, n.adapt= 100,quiet=TRUE)\nupdate(jmodel, 10)\nmcmc_samples <- coda.samples(jmodel, variable.names=c(\"N\"), n.iter=100)\nsummary(mcmc_samples)\n\nIterations = 11:110\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 100 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n       103.310         86.080          6.087          6.099 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n 50.00  58.75  71.50 111.50 325.80 "},{"path":"references.html","id":"references","chapter":"16 References","heading":"16 References","text":"","code":""}]
