[{"path":"index.html","id":"class-1","chapter":"1 Class 1","heading":"1 Class 1","text":"","code":""},{"path":"index.html","id":"probability-fundamentals","chapter":"1 Class 1","heading":"1.1 Probability Fundamentals","text":"Example 1.1  (binomial flips) Consider 100 flips fair coin.probability observing exactly 50 heads 100 flips fair coin?probability observing exactly 50 heads 100 flips fair coin?probability observing 50 heads?probability observing 50 heads?many heads extreme sense less 5% chance observing many heads ?many heads extreme sense less 5% chance observing many heads ?Exercise 1.1  (marbles) Suppose ’s bag containing 50 marbles marble either red yellow.Five marbles randomly selected replacement one found yellow. probability marbles bag yellow?Five marbles randomly selected replacement one found yellow. probability marbles bag yellow?Five marbles randomly selected without replacement found yellow. probability marbles bag yellow?Five marbles randomly selected without replacement found yellow. probability marbles bag yellow?","code":"# (a)\ndbinom(50, 100, prob = 1/2)\n[1] 0.07958924\n# (b)\nsum(dbinom(50:100, 100, prob = 1/2))\n[1] 0.5397946\n1 - pbinom(49, 100, prob = 1/2)\n[1] 0.5397946\npbinom(49, 100, prob = 1/2, lower.tail = FALSE)\n[1] 0.5397946\n# (c)\nqbinom(0.95, 100, prob = 1/2)\n[1] 58\nqbinom(0.05, 100, prob = 1/2, lower.tail = FALSE)\n[1] 58\n1 - pbinom(57, 100, prob = 1/2)\n[1] 0.06660531\n1 - pbinom(58, 100, prob = 1/2)\n[1] 0.04431304"},{"path":"index.html","id":"monte-carlo","chapter":"1 Class 1","heading":"1.2 Monte Carlo","text":"Example 1.2  (gemstones) Suppose \\(n\\) bags labeled \\(1,\\ldots,n\\) bag \\(\\) containing \\(\\) rubies \\(n-\\) diamonds. Suppose bag \\(\\) selected probability directly proportional \\(\\), random gemstone selected bag. probability diamond? Provide theoretical calculation simulated approximation.Example 1.3  (repairs) Suppose costs repair gamma distribution mean $100 standard deviation $50. many items able repair $1000?Exercise 1.2  (ICER) Suppose patient heart failure survival time exponential mean \\(\\theta_N\\) years. Suppose heart transplant \\(\\theta_T\\) operative survival rate, , survive, survival, \\(s_P\\), follows exponential distribution mean \\(\\theta_P\\). Assume operation costs \\(D_{\\text{operation}}\\) dollars post-operative year medical costs immunosuppressants prescriptions amount \\(D_\\text{annual}\\) dollars.literature questions , use Milliman Research Report 2020 U.S. organ tissue transplants possible. Parts (g) (h) relate incremental cost-effectiveness ratio. part (g) requires Monte Carlo simulation.Identify reasonable value \\(\\theta_N\\) literature.Identify reasonable value \\(\\theta_N\\) literature.Calculated monthly mortality based value \\(\\theta_N\\) determined ().Calculated monthly mortality based value \\(\\theta_N\\) determined ().Identify reasonable value \\(\\theta_T\\) literature.Identify reasonable value \\(\\theta_T\\) literature.Identify reasonable value \\(\\theta_P\\) literature.Identify reasonable value \\(\\theta_P\\) literature.Identify reasonable value \\(D_{\\text{operation}}\\) literature.Identify reasonable value \\(D_{\\text{operation}}\\) literature.Identify reasonable value \\(D_{\\text{annual}}\\) literature.Identify reasonable value \\(D_{\\text{annual}}\\) literature.Based values found , estimate expected additional cost per year life gained transplant?Based values found , estimate expected additional cost per year life gained transplant?Calculate ratio expected additional cost expected additional benefit.Calculate ratio expected additional cost expected additional benefit.","code":"n = 13\nPr_given_B = (1:n)/n\nPr_of_B = (1:n)/sum(1:n)\nsum(Pr_given_B * Pr_of_B)\n[1] 0.6923077\n(2 * n + 1)/(3 * n)\n[1] 0.6923077\n\nR = 10^6  # number of random draws\nB = 1:n\nx1 = sample(B, size = R, replace = T, prob = B)\nx2 = sapply(x1, function(x) {\n    rbinom(1, 1, prob = x/n)\n})\nmean(x2)\n[1] 0.691866R = 10^4  # number of random draws\nX.mean = 100\nX.var = 50^2\ns = X.var/X.mean\na = X.mean/s\na * s  #mean\n[1] 100\na * s^2  #variance\n[1] 2500\n\nX = rgamma(20, shape = a, scale = s)\ncumsum(X)\n [1]   56.20787  147.30252  244.49831  296.08107  454.20257\n [6]  494.11205  532.92228  573.29182  725.97754  901.56177\n[11] 1028.94903 1172.80233 1230.39715 1266.52078 1348.17453\n[16] 1404.52642 1512.24501 1568.78050 1617.98163 1755.40670\nwhich(cumsum(X) <= 1000)\n [1]  1  2  3  4  5  6  7  8  9 10\nmax(which(cumsum(X) <= 1000))\n[1] 10\n\nres = rep(as.integer(NA), R)\nfor (i in 1:R) {\n    X = rgamma(20, shape = a, scale = s)\n    res[i] = max(which(cumsum(X) <= 1000))\n}\nmax(res)\n[1] 16\nmean(res)\n[1] 9.5916\nsd(res)\n[1] 1.604515\n\nlibrary(ggplot2)\ndf = data.frame(number = as.factor(res))\nggplot(df, aes(x = number)) + geom_bar()"},{"path":"class-2.html","id":"class-2","chapter":"2 Class 2","heading":"2 Class 2","text":"","code":""},{"path":"class-2.html","id":"diagnostic-testing","chapter":"2 Class 2","heading":"2.1 Diagnostic Testing","text":"Example 2.1  (pregnancy testing) Human Chorionic Gonadotropin (hCG) hormone dramatically increases pregnancy. Levels hormone may also high individuals cancers.Levels hCG can first detected blood test 11 days conception 12-14 days conception urine test, peak first 8-11 weeks pregnancy decline level remainder pregnancy.Non-pregnant women hCG levels < 5 IU/L hCG values > 25 IU/L indicate pregnancy. Levels 5 25 IU/L often indicate early pregnancy, results need interpreted cautiously false positive results can occur range.example simulate hCG data hypothetical population non-pregnant pregnant women early pregnancy, use data study various statistics graphics used classifier assessment.ROC graphic AUC computation using ROCR package1. First “early” pregnancy simulation (mean 20 truncated normal distribution).easily identify suitable threshold graphic, redo graphic biomarker values displayed log scale.Identifying “optimal” cutoff depends costs associated false positives false negatives. can read introduction ROCR. say worse case – false positive pregnancy test false negative pregnancy test? , ’d rather false negative pleasantly surprised later, others might --pleasant surprise. reality, course, “inconclusive” option, doesn’t fit well rigid statistical classifications gives rise various confusion matrix statistics.\nfollowing calculation maximizes Youden’s index2 equal cost false positives false negatives.see cutoff corresponds minimizing sum probability false positive probability false negative demonstrated following code.graph false positives false negatives cutoff original graphic.’s calculation cost associated false positives false negatives, specifically 4 times cost false positive compared false negative.display cutoff graphic showing decreased probability false positive.Next “slightly later” pregnancy simulation (mean 30 truncated normal distribution).compute “optimal” cutoff greater cost false positive.Example 2.2  (PPV prevalence) user-specified values sensitivity specificity, graph positive predictive value range prevalence values.","code":"\nlibrary(truncnorm)\nmygraph = function(mymean) {\n    x <- seq(0, 45, 0.001)\n    y1 <- dlnorm(x, mean = 1.25, sd = 1.5)\n    y2 <- dtruncnorm(x, a = 0, mean = mymean, sd = 5)\n    plot(x, y1, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n        cex.axis = 1.5, lwd = 4, ylab = \"\")\n\n    ind1 = (x >= 5 & x <= 25)\n    polygon(c(5, x[ind1], 25), c(0, y1[ind1], 0), col = \"red\",\n        border = NA)\n    polygon(c(5, x[ind1], 25), c(0, y2[ind1], 0), col = \"red\",\n        border = NA)\n\n    ind2 = (x < 5)\n    polygon(c(0, x[ind2], 5), c(0, y1[ind2], 0), col = \"blue\",\n        border = NA)\n\n    ind3 = (x > 25)\n    polygon(c(25, x[ind3], 45), c(0, y1[ind3], 0), col = \"magenta\",\n        border = NA)\n    polygon(c(25, x[ind3], 45), c(0, y2[ind3], 0), col = \"magenta\",\n        border = NA)\n\n    points(x, y1, type = \"l\", lwd = 4)\n    points(x, y2, type = \"l\", lwd = 4)\n\n    abline(v = 5, lwd = 3, lty = 3)\n    abline(v = 25, lwd = 3, lty = 3)\n    axis(1, at = 5, cex.axis = 1.5)\n    axis(1, at = 25, cex.axis = 1.5)\n}\n\nmygraph(20)  # representing very early on in the pregnancy\nmygraph(30)  # slightly later in the pregnancy\nlibrary(ROCR)\nn = 10^5\ny1 <- rlnorm(n, mean = 1.25, sd = 1.5)\ny2 <- rtruncnorm(n, a = 0, mean = 20, sd = 5)\ny3 <- rtruncnorm(n, a = 0, mean = 30, sd = 5)\ndf = data.frame(hcg = c(y1, y2), preg = c(rep(0, n), rep(1, n)))\npred1 = prediction(df$hcg, df$preg)\nperf1 <- performance(pred1, \"tpr\", \"fpr\")\nauc.perf1 = performance(pred1, measure = \"auc\")@y.values[[1]]\nplot(perf1, colorize = TRUE, downsampling = 10^3)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf1, 3)), adj = 1)\ndf = data.frame(hcg.log = log(c(y1, y2)), preg = c(rep(\"no\",\n    n), rep(\"yes\", n)))\npred2 = prediction(df$hcg.log, df$preg)\nperf2 <- performance(pred2, \"tpr\", \"fpr\")\nauc.perf2 = performance(pred2, measure = \"auc\")@y.values[[1]]\nplot(perf2, colorize = TRUE, downsampling = 10^3)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf2, 3)), adj = 1)cost.perf2 = performance(pred2, \"cost\", cost.fp = 1, cost.fn = 1)\npred2@cutoffs[[1]][which.min(cost.perf2@y.values[[1]])]\n[1] 2.37613\nmycutoff = exp(pred2@cutoffs[[1]][which.min(cost.perf2@y.values[[1]])])\nmycutoff\n[1] 10.76317J = function(x) {\n    mean(y1 > x) + mean(y2 < x)\n}\nJ.vec = Vectorize(J, \"x\")\nx = seq(0, 20, 0.1)\nx[which.min(J.vec(x))]\n[1] 11.2\nmycutoff\n[1] 10.76317\nx <- seq(0, 45, 0.001)\ny1.plot <- dlnorm(x, mean = 1.25, sd = 1.5)\ny2.plot <- dtruncnorm(x, a = 0, mean = 20, sd = 5)\n\nplot(x, y1.plot, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n    cex.axis = 1.5, lwd = 4, ylab = \"\")\n\nind1 = (x >= mycutoff)\npolygon(c(mycutoff, x[ind1], 45), c(0, y2.plot[ind1], 0), col = \"magenta\",\n    border = NA)\npolygon(c(mycutoff, x[ind1], 45), c(0, y1.plot[ind1], 0), col = \"red\",\n    border = NA)\nind2 = (x <= mycutoff)\npolygon(c(0, x[ind2], mycutoff), c(0, y1.plot[ind2], 0), col = \"blue\",\n    border = NA)\npolygon(c(0, x[ind2], mycutoff), c(0, y2.plot[ind2], 0), col = \"orange\",\n    border = NA)\n\npoints(x, y1.plot, type = \"l\", lwd = 4)\npoints(x, y2.plot, type = \"l\", lwd = 4)\n\nabline(v = mycutoff, lwd = 2, lty = 2)\nabline(v = 5, lwd = 1, lty = 3)\nabline(v = 25, lwd = 1, lty = 3)\naxis(1, at = 5, cex.axis = 1.5)\naxis(1, at = 25, cex.axis = 1.5)cost.perf3 = performance(pred2, \"cost\", cost.fp = 4, cost.fn = 1)\npred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])]\n[1] 2.681491\nexp(pred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])])\n[1] 14.60685\nx <- seq(0, 45, 0.001)\ny1.plot <- dlnorm(x, mean = 1.25, sd = 1.5)\ny2.plot <- dtruncnorm(x, a = 0, mean = 20, sd = 5)\nmycutoff = exp(pred2@cutoffs[[1]][which.min(cost.perf3@y.values[[1]])])\n\nplot(x, y1.plot, type = \"n\", xlab = \"hcg (mIU/ml)\", cex.lab = 1.5,\n    cex.axis = 1.5, lwd = 4, ylab = \"\")\n\nind1 = (x >= mycutoff)\npolygon(c(mycutoff, x[ind1], 45), c(0, y2.plot[ind1], 0), col = \"magenta\",\n    border = NA)\npolygon(c(mycutoff, x[ind1], 45), c(0, y1.plot[ind1], 0), col = \"red\",\n    border = NA)\nind2 = (x <= mycutoff)\npolygon(c(0, x[ind2], mycutoff), c(0, y1.plot[ind2], 0), col = \"blue\",\n    border = NA)\npolygon(c(0, x[ind2], mycutoff), c(0, y2.plot[ind2], 0), col = \"orange\",\n    border = NA)\n\npoints(x, y1.plot, type = \"l\", lwd = 4)\npoints(x, y2.plot, type = \"l\", lwd = 4)\n\nabline(v = mycutoff, lwd = 2, lty = 2)\nabline(v = 5, lwd = 1, lty = 3)\nabline(v = 25, lwd = 1, lty = 3)\naxis(1, at = 5, cex.axis = 1.5)\naxis(1, at = 25, cex.axis = 1.5)\ndf = data.frame(hcg.log = log(c(y1, y3)), preg = c(rep(\"no\",\n    n), rep(\"yes\", n)))\npred3 = prediction(df$hcg.log, df$preg)\nperf3 <- performance(pred3, \"tpr\", \"fpr\")\nauc.perf3 = performance(pred3, measure = \"auc\")@y.values[[1]]\nplot(perf3, colorize = TRUE)\ntext(1, 0.1, paste0(\"AUC=\", signif(auc.perf3, 3)), adj = 1)cost.perf4 = performance(pred3, \"cost\", cost.fp = 4, cost.fn = 1)\npred3@cutoffs[[1]][which.min(cost.perf4@y.values[[1]])]\n[1] 3.090492\nexp(pred3@cutoffs[[1]][which.min(cost.perf4@y.values[[1]])])\n[1] 21.9879\nsensitivity = 0.98\nspecificity = 0.999\nprevalence = 10^(-5:-1)\nppv = sensitivity * prevalence/(sensitivity * prevalence + (1 -\n    specificity) * (1 - prevalence))\nplot(log(prevalence, 10), ppv, ylab = \"Positive Predictive Value\",\n    xlab = expression(\"Log\"[10] * \"(Prevalence)\"), pch = 16)"},{"path":"class-3.html","id":"class-3","chapter":"3 Class 3","heading":"3 Class 3","text":"","code":""},{"path":"class-3.html","id":"bayes-theorem-practice","chapter":"3 Class 3","heading":"3.1 Bayes’ Theorem Practice","text":"Example 3.1  (single roll) Suppose friend 3 dice. One 4 sides, one 6 sides, one 8 sides. draws one die random, rolls one time without showing , reports result rolled 2. calculate probability die 4 sided die, probability 6 sided die, probability 8 sided die?Example 3.2  (multiple rolls) Now suppose 6 possible dice, one 4 sides, one 6 sides, one 8 sides, one 10 sides, one 12 sides, one 20 sides. randomly selecting die, die rolled n times outcomes reported. Numerically calculate probabilities number sides randomly selected die.Exercise 3.1  (erroneous dice) Suppose 6 possible dice: one 4 sides, one 6 sides, one 8 sides, one 10 sides, one 12 sides, one 20 sides. randomly selecting die, die rolled n times outcomes reported possible errors reported rolls. assume ’s error given roll, random number 1 20. Incorporate error rate likelihood uniform prior. Given vector rolls, rolls , calculate graph posterior probabilities error rate number sides.","code":"# prior probabilities: P(n=4), P(n=6), P(n=8)\nprob.prior = rep(1/3, 3)\n\n# likelihood probabilities: P(roll=2 | n=4), etc.\nprob.likelihood = c(1/4, 1/6, 1/8)\n\n# posterior probabililities P(n=4 | roll=2)\nprob.posterior = prob.prior * prob.likelihood/sum(prob.prior *\n    prob.likelihood)\n\nprob.posterior\n[1] 0.4615385 0.3076923 0.2307692\n\nc(6, 4, 3)/13\n[1] 0.4615385 0.3076923 0.2307692dice = c(4, 6, 8, 10, 12, 20)\n\nnum.sides = sample(dice, 1)\n\nnum.rolls = 6\n\nrolls = sample(1:num.sides, num.rolls, replace = TRUE)\n\nrolls\n[1] 8 9 7 9 7 9\n\nprior = rep(1/6, 6)\n\nlikelihood = (1/dice)^num.rolls * (max(rolls) <= dice)\n\nmarginal = sum(prior * likelihood)\n\nposterior = (prior * likelihood)/marginal\n\nposterior\n[1] 0.00000000 0.00000000 0.00000000 0.74045390 0.24797651\n[6] 0.01156959\n\nbarplot(posterior, names = dice, main = paste0(\"Actual number of sides: \",\n    num.sides))dice=c(4,6,8,10,12,20)\nnum.sides = sample(dice,1)\nn = 10\nerror.param=runif(1)\nerrors.ind=rbinom(n,1,prob=error.param)\nerrors.values = sample(1:20,sum(errors.ind),replace=T)\n\nrolls = sample(1:num.sides,n,replace=TRUE)\nrolls[which(errors.ind==1)]=errors.values\nrolls\n [1] 7 4 7 3 2 4 7 8 6 7"},{"path":"class-4.html","id":"class-4","chapter":"4 Class 4","heading":"4 Class 4","text":"","code":""},{"path":"class-4.html","id":"beta-binomial","chapter":"4 Class 4","heading":"4.1 Beta-binomial","text":"Exercise 4.1  (Alice Bob simulation) Verify answer Alice Bob homework exercise Monte Carlo simulation.","code":""},{"path":"class-5.html","id":"class-5","chapter":"5 Class 5","heading":"5 Class 5","text":"","code":""},{"path":"class-5.html","id":"covid-19-vaccine-trials","chapter":"5 Class 5","heading":"5.1 COVID-19 Vaccine Trials","text":"Exercise 5.1  (Vaccine Efficacy) Reproduce plot similar Figure 3 (Senn, 2022)3 provide table ten left right endpoints graphic.","code":""},{"path":"class-5.html","id":"bayesian-dice","chapter":"5 Class 5","heading":"5.2 Bayesian Dice","text":"Exercise 5.2  (Loaded Die?) introduced (Berg, 2021)4, consider three-loaded die probability rolling numbers one six 8%, 8%, 64%, 1%, 6%, respectively. die rolled suspect may three loaded die assigning prior probability 50% 50% prior probability given standard fair die equal probabilities. actuality, die probabilities 3%, 17%, 51%, 14%, 14%, 1% (corresponding numbers one six) rolled. Mimic process simulation, , given set rolls simulation, calculate posterior probability rolled die standard die. Let number rolls grow large determine die posterior probability settles ().","code":""},{"path":"class-6.html","id":"class-6","chapter":"6 Class 6","heading":"6 Class 6","text":"","code":""},{"path":"class-6.html","id":"stick-breaking","chapter":"6 Class 6","heading":"6.1 Stick Breaking","text":"Exercise 6.1  (Stick breaking) Given positive integer \\(k\\) positive numbers \\(\\alpha_i\\), \\(=1,\\ldots,k\\), simulate Dirichlet distribution via stick breaking method described (Frigyik et al, 2010).5","code":""},{"path":"class-7.html","id":"class-7","chapter":"7 Class 7","heading":"7 Class 7","text":"","code":""},{"path":"class-7.html","id":"taxicab-problem","chapter":"7 Class 7","heading":"7.1 Taxicab problem","text":"Example 7.1  (Taxicabs JAGS) simple implementation taxicab problem single sample presented using JAGS.Exercise 7.1  (Taxi counter) Suppose taxis sampled following codeKnowing data generating mechanism, construct Bayesian estimate total number taxis (diff(myrange)+1) based data provided taxis. can use JAGS R like.","code":"library(R2jags)\nLoading required package: rjags\nLoading required package: coda\nLinked to JAGS 4.3.0\nLoaded modules: basemod,bugs\n\nAttaching package: 'R2jags'\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nmodel= function(){\nM ~ dcat(p1)\n# sampling distribution is uniform over first N integers\n# use step function to change p1[j] to 0 for j>N\nfor (j in 1:1000) {\np1[j] <- step(N - j + 0.01)/N\n}\nN ~ dcat(p2)\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\ndata=list(\"M\"=100)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"N\",\"M\"), n.chain=2, n.iter=100, n.thin=1, n.burn=0, DIC=FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 1\n   Total graph size: 7007\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmpAKgqWq/model1572d33e5b650.txt\", fit using jags,\n 2 chains, each with 100 iterations (first 0 discarded)\n n.sims = 200 iterations saved\n  mu.vect sd.vect    2.5% 25% 50% 75% 97.5%  Rhat n.eff\nM 100.000   0.000 100.000 100 100 100 100.0 1.000     1\nN 260.485 197.328 102.975 127 191 307 874.1 1.002   200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\nmyrange=sort(rnbinom(2,5,mu=rgamma(2,shape=50,rate=1/200)))\ntaxis=sample(myrange[1]:myrange[2],10,replace=TRUE)"},{"path":"class-8.html","id":"class-8","chapter":"8 Class 8","heading":"8 Class 8","text":"","code":""},{"path":"class-8.html","id":"bayesian-shrinkage","chapter":"8 Class 8","heading":"8.1 Bayesian shrinkage","text":"Exercise 8.1  (Baseball) Using baseball dataset (Efron Morris, 1977),6 compare root mean square deviation James-Stein predictions predictions Bayesian model justified prior. Implementation R, JAGS, Stan fine; reference may helpful implementation JAGS.","code":""},{"path":"class-9.html","id":"class-9","chapter":"9 Class 9","heading":"9 Class 9","text":"","code":""},{"path":"class-9.html","id":"bayes-estimator","chapter":"9 Class 9","heading":"9.1 Bayes estimator","text":"Exercise 9.1  (World cities) database world cities can accessed . excluding cities zero/missing values variable Population missing values variable Country Code, sample \\(n\\) cities randomly sampled without replacement probability proportional variable Population. data provided latitude city, rounded closes integer, number digits variable Population city. estimator actual country function two integers. randomly sampled city rounded integer latitude \\(lat\\), let \\(\\theta\\) country code corresponding city, let \\(d\\) predicted value country code corresponding city, let \\(pop_d\\) total population cities corresponding \\(d\\), let \\(\\Theta_{lat}\\) set country codes city country rounded integer latitude \\(lat\\). Now consider following loss function,\n\\[\nl(\\theta,d)=\n\\begin{cases}\n0, & d=\\theta\\\\\npop_d, & d\\=\\theta \\text{ }d\\\\Theta_{lat}\\\\\n\\infty, & d\\\\\\Theta_{lat}\n\\end{cases}\n\\]\ngoal provide country code predictions minimize sum losses across sampled cities.","code":""},{"path":"class-10.html","id":"class-10","chapter":"10 Class 10","heading":"10 Class 10","text":"","code":""},{"path":"class-10.html","id":"minimax","chapter":"10 Class 10","heading":"10.1 Minimax","text":"Exercise 10.1  (Minimax urns) Consider setup “Minimax urns” example. Prepare program inputs nonegative integer values \\(r_i\\), \\(b_i\\), \\(g_i\\), positive values \\(l_i\\) (\\(=1,2\\) throughout).Identify non-randomized Bayes rules different values \\(\\lambda\\[0,1]\\) produce effective graphic shows Bayes risk Bayesian estimators \\(\\lambda\\) \\([0,1]\\).Let \\(d_j\\), \\(j=1,\\ldots,8\\) represent 8 non-randomized estimators, define \\(S\\subset\\mathbb{R}^2\\) \n\\(S=\\left\\{\\left(R(\\theta_1,d_j),R(\\theta_2,d_j)\\right)\\right\\}_{j=1}^8\\). Graph points \\(S\\) convex hull. Identify closest point convex hull origin, label point \\(M\\).point \\(M\\) (b) corresponds (possibly randomized) minimax estimator \\(d_M\\) can represented \\(d_M=(d_{\\text{red}}, d_{\\text{blue}}, d_{\\text{green}})\\), \\(d_x\\) probability selecting urn 1 color \\(X=x\\) chosen. Determine components \\(d_M\\) graph Bayes risk graphic prepared ().","code":""},{"path":"class-11.html","id":"class-11","chapter":"11 Class 11","heading":"11 Class 11","text":"","code":""},{"path":"class-11.html","id":"prior-distributions","chapter":"11 Class 11","heading":"11.1 Prior distributions","text":"Example 11.1  (Power analysis) consider sample size estimation two-arm randomized trial continuous primary outcome \\(n\\) subjects randomized arm. Assuming normal distribution primary outcome common within-treatment standard deviation \\(\\sigma\\), estimated treatment effect assumed \\(\\mathcal{N}(\\theta,2\\sigma^2/n)\\) distribution. Thus, sample size determination found \n\\[\nn=\\frac{2\\sigma^2}{\\theta^2}\\left(z_{1-\\alpha/2}+z_{1-\\beta}\\right)^2,\n\\]\n\\(z_p=\\Phi^{-1}(p)\\). Solving \\(1-\\beta\\) gives\n\\[\n\\text{Power}=\\Phi\\left(\\sqrt{\\frac{n\\theta^2}{2\\sigma^2}}-z_{1-\\alpha/2}\\right).\n\\]\nSupposing historical data suggests \\(\\theta\\) likely (interpreted 1 standard deviation) 3 7 suggests prior \\(\\theta\\sim\\mathcal{N}(5,2^2)\\). parameter \\(\\sigma\\) estimated around 10 based around 40 observations. leads \\(\\mathrm{GammaSR}(,b)\\) prior \\(\\tau=1/\\sigma^2\\) \\(/b=1/10^2\\) \\(2a=40\\); .e. \\(\\tau\\sim\\mathrm{GammaSR}(20,2000)\\). Another set priors considered: prior \\(\\sigma\\) assumed based 20 observations instead 40 (effectively power prior) leading modified prior distribution \\(\\tau\\sim\\mathrm{GammaSR}(10,1000)\\), prior \\(\\theta\\) assumed mean bias -1 standard deviation 2 constraint \\(\\theta>0\\) thus leading modified prior distribution \\(\\theta\\sim \\mathcal{N}^+(5-1,2^2+2^2)\\).Type error \\(\\alpha\\) set \\(0.05\\). Three quantities tracked: () calculated sample size \\(n\\) 90% power, (ii) power based \\(n=84\\) (frequentest estimate fixed \\(\\theta=5\\), \\(\\sigma=10\\), 90% power), (iii) \\(n=84\\), probability power least 70%.Example 11.2  (GREAT study) region early trial (GREAT) found patients suspected acute myocardial infarction lower 3-month mortality treated early .Let \\(r_j\\), \\(n_j\\), \\(p_j\\) denote number deaths, total number patients, underlying mortality rate, respectively, group \\(j\\\\{1,2\\}\\) (1=anistreplase; 2=placebo). interested conducting inference log-odds ratio mortality anistreplase group compared placebo; .e. \n\\[\n\\theta=\\log\\left\\{\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\right\\}=\\text{logit}(p_1) - \\text{logit}(p_2)\n\\]\nnatural estimator \\(\\theta\\) \n\\[\n\\hat{\\theta}=\\log\\left\\{\\frac{r_1/(n_1-r_1)}{r_2/(n_2-r_2)}\\right\\} \\approx -0.753\n\\]\n\\[\n\\text{Var}(\\hat\\theta)\\approx \\frac{1}{r_1}+\\frac{1}{r_2}+\\frac{1}{n_1-r_1}+\\frac{1}{n_2-r_2}\\approx 0.135\n\\]following Bayesian models considered.Model (normal dist effect, uniform prior): \\(\\hat\\theta\\sim\\mathcal{N}(\\theta,0.135)\\) \\(\\theta\\sim\\text{Uniform}(-10,10)\\).Model B (binomial dist rates, Jeffreys priors): \\(r_j\\sim\\text{Binomial}(p_j,n_j)\\) \\(p_j\\sim\\Beta(.5,.5)\\), \\(j=1,2\\).Model C (binomial dist rates, logit transform, clinical prior): parameters \\(p_1\\) \\(p_2\\) reparameterized terms \\(\\alpha\\) \\(\\theta\\) \n\\[\n\\begin{split}\n\\text{logit}(p_1) &= \\alpha + \\theta/2\\\\\n\\text{logit}(p_2) &= \\alpha - \\theta/2\n\\end{split}\n\\]\n\\(\\alpha\\) nuisance parameter given practically flat prior: \\(\\alpha\\sim\\mathcal{N}(0,100^2)\\). “clinical” prior \\(\\theta\\) based expert elicitation: senior cardiologist, informed one unpublished two published trials, expressed belief “expectation 15-20% reduction mortality highly plausible, extremes benefit 40% relative reduction unlikely”.translated 95% interval odds ratio (.6,1), corresponds interval (-.51,0) log-odds scale. normal distribution property leads \\(\\theta\\sim\\mathcal{N}(\\mu_0,\\sigma_{0}^2)\\), \\(\\mu_0=(-.51+0)/2=-.26\\) \\(\\sigma_0=.26/1.96\\approx .13\\).Model D (binomial dist rates, logit transform, skeptical prior): model follows approach Model C ``skeptical’’ prior placed \\(\\theta\\) avoid early stopping trials due fortuitously positive results. Specifically, prior \\(\\theta\\) constructed 95% confidence interval (.5, 2) odds ratio scale, equivalent interval (-.69,69) log-odds scale. normal distribution property leads \\(\\theta\\sim\\mathcal{N}(0,.35^2)\\).","code":"\nlibrary(rjags)\n\nmodel =\"\nmodel{\n\n tau ~ dgamma(20, 2000)\n tauDis ~ dgamma(10, 1000) # discounted by 2\n \n sigma <- 1/sqrt(tau) \n sigmaDis <- 1/sqrt(tauDis) \n \n theta ~ dnorm(5, 0.25) \n thetaDis ~ dnorm(4, 0.125) I(0,)  # 4 added to var and shifted by -1, constrained to be >0\n \n n <- 2*pow((1.28 + 1.96)*sigma/theta, 2) # n for 90% power \n power <- phi(sqrt(84/2)*theta/sigma - 1.96) # power for n = 84 \n p70 <- step(power - 0.7) # Pr(power > 70%)\n \n nDis <- 2*pow((1.28 + 1.96)*sigmaDis/thetaDis, 2) # n for 90% power \n powerDis <- phi(sqrt(84/2)*thetaDis/sigmaDis - 1.96) # power for n = 84 \n p70Dis <- step(powerDis - 0.7) # Pr(power > 70%)\n }\"\n\n\ndata=list()\njmodel <- jags.model(textConnection(model), data = data,n.chains = 3, n.adapt= 100,quiet=TRUE)\nupdate(jmodel, 100)\nmcmc_samples <- coda.samples(jmodel, variable.names=c(\"n\",\"power\",\"p70\",\"nDis\",\"powerDis\",\"p70Dis\"), n.iter=1000)\nplot(mcmc_samples)summary(mcmc_samples)\n\nIterations = 101:1100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean        SD  Naive SE Time-series SE\nn        1.416e+03 3.457e+04 6.312e+02      6.312e+02\nnDis     4.274e+07 2.326e+09 4.246e+07      4.246e+07\np70      7.007e-01 4.580e-01 8.363e-03      8.513e-03\np70Dis   5.467e-01 4.979e-01 9.090e-03      9.087e-03\npower    7.706e-01 2.661e-01 4.859e-03      4.883e-03\npowerDis 6.602e-01 3.259e-01 5.950e-03      5.950e-03\n\n2. Quantiles for each variable:\n\n             2.5%     25%      50%      75% 97.5%\nn        23.90597 53.0114  88.2762 166.9580  1730\nnDis     20.83304 58.8898 123.6087 317.4457 13747\np70       0.00000  0.0000   1.0000   1.0000     1\np70Dis    0.00000  0.0000   1.0000   1.0000     1\npower     0.10199  0.6324   0.8850   0.9829     1\npowerDis  0.04394  0.3846   0.7614   0.9719     1(mat=matrix(c(13,150,23,125),nrow=2,ncol=2,dimnames=list(c(\"death\",\"no death\"),c(\"anistreplase\",\"placebo\"))))\n         anistreplase placebo\ndeath              13      23\nno death          150     125\nfisher.test(mat)\n\n    Fisher's Exact Test for Count Data\n\ndata:  mat\np-value = 0.05002\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.2104046 1.0183476\nsample estimates:\nodds ratio \n 0.4721467 model= function(){\n\n  pr.mean[1] <- -0.26\n  pr.sd[1] <- 0.13 # clinical prior\n  \n  pr.mean[2] <- 0\n  pr.sd[2] <- 0.35 # skeptical prior\n  \n  \n  ## Likelihoods\n  \n  # Model A\n  theta.mle ~ dnorm(thetaA, 1/.135) \n  \n  # Model B\n  r.rep[1,1] ~ dbin(pB[1],n.rep[1,1])\n  r.rep[1,2] ~ dbin(pB[2],n.rep[1,2])\n  \n  thetaB <- logit(pB[1]) - logit(pB[2])\n  \n  # Model C\n  r.rep[2,1] ~ dbin(pC[1],n.rep[1,1])\n  r.rep[2,2] ~ dbin(pC[2],n.rep[1,2])\n  \n  logit(pC[1]) <- alphaC + thetaC/2\n  logit(pC[2]) <- alphaC - thetaC/2\n  \n  # Model D\n  r.rep[3,1] ~ dbin(pD[1],n.rep[1,1])\n  r.rep[3,2] ~ dbin(pD[2],n.rep[1,2])\n  \n  logit(pD[1]) <- alphaD + thetaD/2\n  logit(pD[2]) <- alphaD - thetaD/2\n  \n  ## priors\n  \n  # Model A\n  thetaA ~ dunif(-10, 10) # locally uniform prior\n  \n  # Model B\n  pB[1] ~ dbeta(0.5, 0.5) \n  pB[2] ~ dbeta(0.5, 0.5) \n  \n  # Model C (clinical prior)\n  alphaC ~ dnorm(0, 0.0001)\n  thetaC ~ dnorm(-.26, 1/pow(.13, 2))\n\n  # Model D (skeptical prior)\n  alphaD ~ dnorm(0, 0.0001)\n  thetaD ~ dnorm(0, 1/pow(.35, 2))\n}\n\nr=c(13, 23)\nn=c(163, 148)\nr.rep=array(rep(r,each=3),dim=c(3,2))\nn.rep=array(rep(n,each=3),dim=c(3,2))\n\nr.rep\n     [,1] [,2]\n[1,]   13   23\n[2,]   13   23\n[3,]   13   23\nn.rep\n     [,1] [,2]\n[1,]  163  148\n[2,]  163  148\n[3,]  163  148\n\ndata=list(r.rep = r.rep, n.rep = n.rep,theta.mle= -0.753)\n\n\nlibrary(R2jags)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"thetaA\",\"thetaB\",\"thetaC\",\"thetaD\"), n.chain=2, n.iter=5000, n.thin=1, n.burn=100, DIC=FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 7\n   Unobserved stochastic nodes: 7\n   Total graph size: 50\n\nInitializing model\nfit.mcmc <- as.mcmc(fit)\nplot(fit.mcmc)summary(fit.mcmc)\n\nIterations = 101:5000\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 4900 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean     SD Naive SE Time-series SE\nthetaA -0.7530 0.3741 0.003779       0.004664\nthetaB -0.7473 0.3711 0.003749       0.004767\nthetaC -0.3171 0.1227 0.001239       0.002252\nthetaD -0.3737 0.2557 0.002583       0.009054\n\n2. Quantiles for each variable:\n\n          2.5%     25%     50%     75%    97.5%\nthetaA -1.4841 -1.0046 -0.7609 -0.5050 -0.01045\nthetaB -1.5069 -0.9924 -0.7388 -0.4951 -0.04037\nthetaC -0.5600 -0.4000 -0.3171 -0.2329 -0.07888\nthetaD -0.8795 -0.5459 -0.3697 -0.2014  0.12704\nmat=as.matrix(as.mcmc(fit))\nboxplot(mat)\nabline(h=0)\n\nlibrary(\"bayesplot\")\nlibrary(\"ggplot2\")\nplot_title <- ggtitle(\"Posterior distributions\",\n                      \"with medians and 95% intervals\")\nmcmc_areas(mat,\n           pars = c(\"thetaA\", \"thetaB\", \"thetaC\", \"thetaD\"),\n           prob = 0.95) + plot_title"},{"path":"class-11.html","id":"bayes-factor","chapter":"11 Class 11","heading":"11.2 Bayes factor","text":"Example 11.3  (Paul psychic octopus) 2020 soccer World Cup competition, Paul psychic octopus correctly made 8 8 predictions winner. Let \\(H_0\\) represent hypothesis predictions coincidence, let \\(H_1\\) represent hypothesis Paul psychic ability. specifically, ignore possibility draw assume predictions follow binomial distribution parameter \\(\\theta\\) representing probability correct prediction. wish compare following hypotheses\n\\[\n\\begin{split}\n    &H_0: \\theta=.5\\\\\n    &H_1: \\theta\\sim\\text{Uniform}(.5,1)\n\\end{split}\n\\]particular, notice hypothesis testing problem translated inference problem.","code":"model <- function() { \n  q[1] <- 0.5 # prior probabilities\n  q[2] <- 0.5 \n  \n  theta[1] <- 0.5 # H0\n  theta[2] ~ dunif(0.5, 1) # H1\n\n  r ~ dbin(theta[pick], n) # likelihood\n  pick ~ dcat(q[])\n  psychic <- pick - 1 # 1 if psychic, 0 otherwise\n  }\n\nData <- list(r = 8, n = 8)\nfit <- jags(Data, model = model, param = c(\"theta\",\n    \"psychic\"), n.chain = 2, n.iter = 10000, n.thin = 1,\n    n.burn = 0, DIC = FALSE)\nmodule glm loaded\nmodule dic loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 2\n   Total graph size: 9\n\nInitializing model\nprint(fit)\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//Rtmp5yyCFv/model1518d707f84d2.txt\", fit using jags,\n 2 chains, each with 10000 iterations (first 0 discarded)\n n.sims = 20000 iterations saved\n         mu.vect sd.vect  2.5%   25%   50%   75% 97.5%\npsychic    0.983   0.127 1.000 1.000 1.000 1.000 1.000\ntheta[1]   0.500   0.000 0.500 0.500 0.500 0.500 0.500\ntheta[2]   0.900   0.089 0.663 0.857 0.925 0.969 0.997\n          Rhat n.eff\npsychic  1.001 20000\ntheta[1] 1.000     1\ntheta[2] 1.005  1200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\nattach.jags(fit)\nhist(theta[,2])"},{"path":"class-12.html","id":"class-12","chapter":"12 Class 12","heading":"12 Class 12","text":"","code":""},{"path":"class-12.html","id":"information-theory","chapter":"12 Class 12","heading":"12.1 Information Theory","text":"Exercise 12.1  (五音不全 - part 1) Wordle popular interactive word game given rise numerous Wordle variants. exercise seeks identify optimal strategies (using information theory) solve Wordle variant constructed just class termed 五音不全. ’s works:set \\(n\\) four character Chinese idioms (成语) randomly selected without replacement according provided probability distribution (roughly proportional publication frequency). idiom mapped four digit signature digit corresponds pinyin tone four characters (neutral tone considered “fifth” tone). goal guess four-digit signature randomly selected idioms. Interactive feedback provided typical Wordle puzzle. start initial four-digit guess, feedback provided indicating digits correct location, digits present wrong location, remaining digits present answer.ultimate goal produce two functions automatically provide subsequent guesses based feedback compare_words function. exercise, follow approach spirit Grant Sanderson’s 3Blue1Brown videos identify optimal initial guess. next assignment asked generate function inputs previous guesses feedback data outputs next guess.Primitive forms functions provided along mock contest. primitive functions swapped replaced prepared functions similar contest run. scores rounds averaged individual smallest average (efficient routine) gifted prize basket 美亞超市 keeping Chinese theme. Shiny simulation demonstrate wordle variant  Comparison functions  Example functions  Mock contest ","code":"\n\nload(\"mydict2.RData\")\n\ncompare_words = function(target_str, guess_str) {\n    if ((nchar(target_str) != 4) | (nchar(guess_str) != 4)) {\n        stop(\"target and guess string must be length 4.\")\n    }\n\n    target = strsplit(target_str, \"\")[[1]]\n    guess = strsplit(guess_str, \"\")[[1]]\n    result = character(nchar(guess_str))\n\n    for (i in 1:4) {\n        if (guess[i] == target[i]) {\n            result[i] = \"correct\"\n            target[i] = \"\"\n            guess[i] = \"\"\n        }\n    }\n    for (i in 1:4) {\n        if (guess[i] != \"\") {\n            if (is.element(guess[i], target)) {\n                result[i] = \"in-word\"\n                target[which(target == guess[i])[1]] = \"\"\n                next\n            }\n            result[i] = \"not-in-word\"\n        }\n    }\n    result\n}\n\ncheck_words = function(target_str, guess_str) {\n    compare_result = compare_words(target_str, guess_str)\n    result = \"keep guessing\"\n    if (all(compare_result == \"correct\")) {\n        result = \"solved\"\n    }\n    result\n}\nf.init1 = function(word_num, score, words) {\n    \"1234\"\n}\nf.init2 = function(word_num, score, words) {\n    \"1324\"\n}\nf.init3 = function(word_num, score, words) {\n    \"1243\"\n}\nf.init4 = function(word_num, score, words) {\n    \"1233\"\n}\nf.init5 = function(word_num, score, words) {\n    \"1142\"\n}\n\n\nf.main1 = function(word_num, scores.current, words, guess_number,\n    myguesses, myfeedback) {\n\n    correct = rep(as.character(NA), 4)\n    chars = NA\n\n    mymat = matrix(\"maybe\", nrow = 5, ncol = 4)\n    rownames(mymat) = as.character(1:5)\n    colnames(mymat) = as.character(1:4)\n\n    for (i in 1:guess_number) {\n        nums = strsplit(myguesses[i], \"\")[[1]]\n        pos = myfeedback[i, ]\n\n        cor = which(pos == \"correct\")\n        iw = which(pos == \"in-word\")\n\n        niw = setdiff(unique(nums[pos == \"not-in-word\"]), c(nums[cor],\n            nums[iw]))\n        niw2 = intersect(c(nums[cor], nums[iw]), unique(nums[pos ==\n            \"not-in-word\"]))\n\n        if (length(niw2) > 0) {\n            for (j in 1:length(niw2)) {\n                mymat[niw2[j], which(pos == \"not-in-word\" & nums ==\n                  niw2[j])[1]] = \"no\"\n            }\n        }\n\n        if (length(niw) > 0) {\n            for (j in 1:length(niw)) {\n                mymat[niw[j], ] = \"no\"\n            }\n        }\n\n        if (length(cor) > 0) {\n            correct[cor] = nums[cor]\n            if (sum(is.na(chars)) > 0) {\n                chars = nums[cor]\n            } else {\n                chars = append(chars, nums[cor])\n            }\n            for (j in 1:length(cor)) {\n                mymat[, cor[j]] = \"no\"\n                mymat[nums[cor[j]], cor[j]] = \"yes\"\n            }\n        }\n\n        if (length(iw) > 0) {\n            if (sum(is.na(chars)) > 0) {\n                chars = nums[iw]\n            } else {\n                chars = append(chars, nums[iw])\n            }\n\n            for (j in 1:length(iw)) {\n                mymat[nums[iw[j]], iw[j]] = \"no\"\n            }\n        }\n\n        chars = setdiff(chars, correct)\n\n    }  #end of i loop \n\n    chars.og = chars\n    mymat.og = mymat\n    done = FALSE\n\n    while (!done) {\n        mymat = mymat.og\n        chars = chars.og\n        out = correct\n        ind = which(is.na(correct))\n\n        if (length(ind) > 0) {\n            for (j in 1:length(ind)) {\n\n                if (length(chars) == 0) {\n                  mypos = which(is.na(out))[1]\n                  mynum = as.character(which(mymat[, mypos] ==\n                    \"maybe\"))[1]\n                  out[mypos] = mynum\n                  mymat[, mypos] = \"X\"\n                }\n\n                if (length(chars) > 0) {\n                  n.maybe = sum(mymat[chars[1], ] == \"maybe\")\n                  if (n.maybe > 0) {\n                    mypos = sample(as.character(which(mymat[chars[1],\n                      ] == \"maybe\")), 1)\n                    out[as.numeric(mypos)] = chars[1]\n                    mymat[, as.numeric(mypos)] = \"X\"\n                    chars = setdiff(chars, chars[1])\n                  }\n                }\n\n            }\n        }\n\n        if (sum(!is.na(out)) == 4) {\n            done = TRUE\n        }\n    }  #end of while  \n\n    paste(out, collapse = \"\")\n\n}\n\nf.main2 = f.main3 = f.main4 = f.main5 = f.main1myseed = 31428212  # seed will be changed for competition\nset.seed(myseed)\nn = 1000\ncomp_words = mydict[sample(1:dim(mydict)[1], n, prob = mydict$freq,\n    replace = FALSE), \"sig\"]\nguesses = array(as.character(NA), dim = c(n, 10, 5))\nfeedback = array(as.character(NA), dim = c(n, 10, 4, 5))\nscores = matrix(0, nrow = n, ncol = 5)\n\nfor (word_num in 1:n) {\n    words = if (word_num == 1) {\n        NA\n    } else {\n        words = comp_words[1:(word_num - 1)]\n    }\n    scores.current = apply(matrix(scores[1:word_num, ], ncol = 5),\n        2, sum)\n\n    for (i in 1:5) {\n        guess_number = 1\n        f.init = get(paste0(\"f.init\", i))\n        guess = f.init(word_num, scores.current, words)\n        guesses[word_num, 1, i] = guess\n        res = check_words(comp_words[word_num], guess)\n        feedback[word_num, guess_number, , i] = compare_words(comp_words[word_num],\n            guess)\n\n        while (res == \"keep guessing\" & guess_number <= 9) {\n            myguesses = guesses[word_num, 1:guess_number, i]\n            myfeedback = matrix(feedback[word_num, 1:guess_number,\n                , i], nrow = guess_number, ncol = 4)\n            f.main = get(paste0(\"f.main\", i))\n            guess = f.main(word_num, scores.current, words, guess_number,\n                myguesses, myfeedback)\n            guess_number = guess_number + 1\n            guesses[word_num, guess_number, i] = guess\n            res = check_words(comp_words[word_num], guess)\n            feedback[word_num, guess_number, , i] = compare_words(comp_words[word_num],\n                guess)\n            res\n        }\n\n        scores[word_num, i] = guess_number\n    }\n\n}\n\napply(scores, 2, mean)\n[1] 2.879 2.822 2.878 3.452 3.203"},{"path":"class-13.html","id":"class-13","chapter":"13 Class 13","heading":"13 Class 13","text":"Exercise 13.1  (五音不全 - part 2) continuation previous exercise, generate function inputs previous guesses feedback data outputs next guess. Example inputs outputs provided. two finally submitted functions able smoothly run mock contest previously provided. Sample input output f.init function  Sample input output f.main function ","code":"word_num\n[1] 5\nscores.current\n[1] 14 12 15 17 11\nwords\n[1] \"4244\" \"2224\" \"4324\" \"3511\"\nf.init(word_num,scores.current,words)\n[1] \"1142\"word_num\n[1] 5\nscores.current\n[1] 14 12 15 17 11\nwords\n[1] \"4244\" \"2224\" \"4324\" \"3511\"\nguess_number\n[1] 3\nmyguesses\n[1] \"1142\" \"4211\"\nmyfeedback\n     [,1]      [,2]          [,3]          [,4]     \n[1,] \"in-word\" \"not-in-word\" \"in-word\"     \"in-word\"\n[2,] \"correct\" \"correct\"     \"not-in-word\" \"correct\"\n\nf.main(word_num,scores.current,words,guess_number,myguesses,myfeedback)\n[1] \"4221\"\n\ncheck_words(comp_words[word_num],\"4221\")\n[1] \"solved\""},{"path":"to-be-incorporated.html","id":"to-be-incorporated","chapter":"14 To Be Incorporated","heading":"14 To Be Incorporated","text":"","code":""},{"path":"to-be-incorporated.html","id":"jags","chapter":"14 To Be Incorporated","heading":"14.1 JAGS","text":"","code":"library(R2jags)\nLoading required package: rjags\nLoading required package: coda\nLinked to JAGS 4.3.0\nLoaded modules: basemod,bugs\n\nAttaching package: 'R2jags'\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nmymodel= function(){\nfor ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\nn <- 50\ntheta.true <- .3\ny.sim <- rbinom(n, 1, theta.true)\n\nmydata = list(    \n  y = y.sim ,\n  Ntotal = n \n)\n\n\n\nfit <- jags(data=mydata, model=mymodel, parameters.to.save = c(\"theta\"), n.chain=2, n.iter=200, n.thin=1, n.burn=100)\nmodule glm loaded\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmphaFY5e/model12f5f37eb986b.txt\", fit using jags,\n 2 chains, each with 200 iterations (first 100 discarded)\n n.sims = 200 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%\ntheta      0.325   0.062  0.201  0.284  0.329  0.369  0.433\ndeviance  63.604   1.244 62.688 62.799 63.201 63.903 66.765\n          Rhat n.eff\ntheta    1.045    82\ndeviance 1.132    47\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 0.8 and DIC = 64.4\nDIC is an estimate of expected predictive error (lower deviance is better).library(R2jags)\n\nmodel= function(){\nM ~ dcat(p1)\n# sampling distribution is uniform over first N integers\n# use step function to change p1[j] to 0 for j>N\nfor (j in 1:1000) {\np1[j] <- step(N - j + 0.01)/N\n}\nN ~ dcat(p2)\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\ndata=list(\"M\"=100)\nfit <- jags(data=data, model=model,parameters.to.save=c(\"N\",\"M\"), n.chain=2, n.iter=100, n.thin=1, n.burn=0, DIC=FALSE)\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 1\n   Unobserved stochastic nodes: 1\n   Total graph size: 7007\n\nInitializing model\nfit\nInference for Bugs model at \"/var/folders/fy/_0t49sys0713k84msqwk44fc0000gp/T//RtmphaFY5e/model12f5f261fc56b.txt\", fit using jags,\n 2 chains, each with 100 iterations (first 0 discarded)\n n.sims = 200 iterations saved\n  mu.vect sd.vect    2.5%    25% 50%    75%   97.5%  Rhat\nM  100.00   0.000 100.000 100.00 100 100.00 100.000 1.000\nN  259.14 199.757 102.975 130.75 182 292.25 856.125 0.996\n  n.eff\nM     1\nN   200\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).library(rjags)\nmodel_string <- \"\nmodel {\nM ~ dcat(p1)\nfor (j in 1:1000) {\np1[j] <- (pow(j*step(N - j + 0.01)/N,2)-pow((j-1)*step(N - j  + 0.01)/N,2))\n}\nN ~ dcat(p2[])\nfor (j in 1:1000) {\nrecip[j] <- 1/j\np2[j] <- recip[j]/sum.recip\n}\nsum.recip <- sum(recip)\n}\"\n\ndata=list(\"M\"=50)\njmodel <- jags.model(textConnection(model_string), data = data,inits=list(N=100),n.chains = 2, n.adapt= 100,quiet=TRUE)\nupdate(jmodel, 10)\nmcmc_samples <- coda.samples(jmodel, variable.names=c(\"N\"), n.iter=100)\nsummary(mcmc_samples)\n\nIterations = 11:110\nThinning interval = 1 \nNumber of chains = 2 \nSample size per chain = 100 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean             SD       Naive SE Time-series SE \n       103.310         86.080          6.087          6.099 \n\n2. Quantiles for each variable:\n\n  2.5%    25%    50%    75%  97.5% \n 50.00  58.75  71.50 111.50 325.80 "},{"path":"references.html","id":"references","chapter":"15 References","heading":"15 References","text":"","code":""}]
